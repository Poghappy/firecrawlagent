# Firecrawl 生态系统完整配置指南

> **版本**: v1.0
> **更新时间**: 2025-10-27
> **配置难度**: 🟡 中等（30-60 分钟）
> **适用项目**: FireShot + HawaiiHub

---

## 📦 Firecrawl 生态系统概览

根据 [Firecrawl 组织仓库](https://github.com/orgs/firecrawl/repositories)分析，核心项目包括：

### 🌟 核心仓库（必装）

| 仓库                     | Stars | 用途                      | 技术栈     |
| ------------------------ | ----- | ------------------------- | ---------- |
| **firecrawl**            | 21k⭐ | 主项目（自部署）          | TypeScript |
| **firecrawl-docs**       | 138⭐ | 官方文档                  | Markdown   |
| **data-connectors**      | 95⭐  | LLM-ready 数据连接器      | TypeScript |
| **mcp-server-firecrawl** | 41⭐  | MCP 服务器（Cursor 集成） | TypeScript |

### 🎯 高级工具（推荐）

| 仓库                       | Stars | 用途                 |
| -------------------------- | ----- | -------------------- |
| **open-researcher**        | 285⭐ | 视觉 AI 研究助手     |
| **firestarter**            | 509⭐ | AI 聊天机器人（RAG） |
| **llmstxt-generator**      | 478⭐ | 生成 llms.txt 文件   |
| **firecrawl-app-examples** | 581⭐ | 完整应用示例         |
| **firesearch**             | 401⭐ | AI 深度研究工具      |

---

## 🚀 快速配置方案（推荐）

### 方案 A：云 API + MCP（最简单） ⭐推荐

**适用场景**: 快速开发、HawaiiHub 生产环境

```bash
# 1. 安装 Python SDK
pip3 install --break-system-packages firecrawl-py python-dotenv

# 2. 安装 Node.js SDK（可选）
npm install @mendable/firecrawl-js

# 3. 配置环境变量
echo "FIRECRAWL_API_KEY=fc-your-key-here" >> .env

# 4. MCP 服务器已配置（在 ~/.cursor/mcp.json）
# 无需额外安装
```

**优势**:

- ✅ 零基础设施成本
- ✅ 内置反爬绕过
- ✅ 自动扩展
- ✅ Cursor 原生支持

**成本**: $0（免费层 500 页/月）→ $19/月起（Business）

---

### 方案 B：Data Connectors（数据集成）

**适用场景**: 需要集成多种数据源（Google Drive、GitHub、Notion 等）

```bash
# 1. 安装 Data Connectors
npm install @mendable/data-connectors

# 2. 创建 TypeScript 项目（如果还没有）
mkdir firecrawl-integration && cd firecrawl-integration
npm init -y
npm install typescript @types/node tsx --save-dev

# 3. 配置 tsconfig.json
cat > tsconfig.json << 'EOF'
{
  "compilerOptions": {
    "target": "ES2022",
    "module": "commonjs",
    "lib": ["ES2022"],
    "moduleResolution": "node",
    "esModuleInterop": true,
    "strict": true,
    "skipLibCheck": true,
    "outDir": "./dist",
    "rootDir": "./src"
  }
}
EOF

# 4. 创建示例文件
mkdir -p src
```

**支持的数据源**（11 种）:

- ✅ 文件（.md, .txt, .csv, .pdf）
- ✅ GitHub（公开/私有仓库）
- ✅ Google Drive
- ✅ Notion（需授权访问）
- ✅ 纯文本
- ✅ Web Scraper（Crawler、URLs、Sitemap）
- ✅ Zendesk
- ✅ YouTube（频道/单视频）
- ✅ Jira
- ✅ Confluence（Wiki 页面）
- ✅ Salesforce（账户、文章、联系人、交易、工单）

---

### 方案 C：自部署（高级用户）

**适用场景**: 需要完全控制、私有化部署

```bash
# 1. 克隆主仓库
git clone https://github.com/firecrawl/firecrawl.git
cd firecrawl

# 2. 使用 Docker Compose 部署
docker-compose up -d

# 3. 配置环境变量
cp .env.example .env
# 编辑 .env 文件

# 4. 访问
# http://localhost:3002
```

**要求**:

- Docker + Docker Compose
- Redis
- PostgreSQL
- 2GB+ RAM

---

## 📋 详细配置步骤

### Step 1: 环境变量配置

创建 `.env` 文件（基于 data-connectors 的 `example.env`）：

```bash
# ============ Firecrawl 云 API ============
FIRECRAWL_API_KEY=fc-xxxxxxxxxxxxxxxxxxxxxxxx

# ============ Nango 授权（可选）============
# 用于 Google Drive、GitHub 等 OAuth 认证
NANGO_SECRET_KEY=your-nango-secret-key
NANGO_CONNECTION_ID_TEST=your-test-connection-id

# ============ Google Drive（可选）============
GOOGLE_DRIVE_CLIENT_ID=your-client-id.apps.googleusercontent.com
GOOGLE_DRIVE_CLIENT_SECRET=your-client-secret
GOOGLE_DRIVE_REDIRECT_URI=http://localhost:3000/auth/callback

# ============ Web Scraping（可选）============
SCRAPING_BEE_API_KEY=your-scraping-bee-key

# ============ 成本控制 ============
FIRECRAWL_DAILY_BUDGET=10.0
FIRECRAWL_TIMEOUT=60

# ============ 备用密钥（轮换）============
FIRECRAWL_API_KEY_BACKUP_1=fc-xxxxxxxxx
FIRECRAWL_API_KEY_BACKUP_2=fc-xxxxxxxxx
FIRECRAWL_API_KEY_BACKUP_3=fc-xxxxxxxxx
```

**获取 API Key**:

1. 访问 https://www.firecrawl.dev/signin
2. 注册/登录
3. 进入 Dashboard → API Keys
4. 点击 "Create New Key"
5. 复制密钥到 `.env`

---

### Step 2: Data Connectors 使用示例

创建 `src/connectors-demo.ts`:

```typescript
import { createDataConnector } from '@mendable/data-connectors'

// ============ 示例 1: Web Scraper ============
async function scrapeWebsite() {
  const webConnector = createDataConnector({
    provider: 'web-scraper',
  })

  webConnector.setOptions({
    urls: ['https://www.hawaiinewsnow.com/', 'https://www.staradvertiser.com/'],
    mode: 'single_urls',
  })

  const documents = await webConnector.getDocuments()

  console.log(`✅ 爬取了 ${documents.length} 个文档`)
  documents.forEach((doc) => {
    console.log(`- ${doc.metadata.sourceURL}: ${doc.content.substring(0, 100)}...`)
  })

  return documents
}

// ============ 示例 2: Google Drive ============
async function fetchFromGoogleDrive() {
  const gdConnector = createDataConnector({
    provider: 'google-drive',
  })

  // 方法 1: OAuth Token
  await gdConnector.authorize({
    access_token: process.env.GOOGLE_DRIVE_ACCESS_TOKEN!,
  })

  // 或方法 2: Nango（推荐，自动处理 OAuth）
  // await gdConnector.authorizeNango({
  //   nango_connection_id: process.env.NANGO_CONNECTION_ID_TEST!
  // });

  const documents = await gdConnector.getDocuments()

  console.log(`✅ 从 Google Drive 获取了 ${documents.length} 个文档`)

  return documents
}

// ============ 示例 3: GitHub ============
async function fetchFromGitHub() {
  const ghConnector = createDataConnector({
    provider: 'github',
  })

  await ghConnector.authorize({
    access_token: process.env.GITHUB_ACCESS_TOKEN!,
  })

  ghConnector.setOptions({
    owner: 'firecrawl',
    repo: 'firecrawl',
    branch: 'main',
  })

  const documents = await ghConnector.getDocuments()

  console.log(`✅ 从 GitHub 获取了 ${documents.length} 个文档`)

  return documents
}

// ============ 示例 4: YouTube ============
async function fetchFromYouTube() {
  const ytConnector = createDataConnector({
    provider: 'youtube',
  })

  ytConnector.setOptions({
    videoUrl: 'https://www.youtube.com/watch?v=qk1iQKHaKiI',
    // 或频道：channelUrl: "https://www.youtube.com/@firecrawl"
  })

  const documents = await ytConnector.getDocuments()

  console.log(`✅ 从 YouTube 获取了 ${documents.length} 个文档（含字幕）`)

  return documents
}

// ============ 主函数 ============
async function main() {
  console.log('🔥 Firecrawl Data Connectors 演示\n')

  try {
    // 运行 Web Scraper 示例
    await scrapeWebsite()

    // 其他示例需要配置相应的 API 密钥
    // await fetchFromGoogleDrive();
    // await fetchFromGitHub();
    // await fetchFromYouTube();
  } catch (error) {
    console.error('❌ 错误:', error)
  }
}

main()
```

**运行示例**:

```bash
# 方法 1: 使用 tsx（推荐）
npx tsx src/connectors-demo.ts

# 方法 2: 编译后运行
npm run build
node dist/connectors-demo.js
```

---

### Step 3: 数据格式说明

所有连接器返回统一的 `Document` 对象：

```typescript
export class Document {
  content: string // 文档内容（Markdown 格式）
  provider: string // 数据源提供者（如 "web-scraper"）
  id?: string // 唯一标识符
  createdAt?: Date // 创建时间
  updatedAt?: Date // 更新时间
  type?: string // 文档类型
  metadata: {
    sourceURL?: string // 来源 URL（几乎总是包含）
    [key: string]: any // 其他元数据
  }
}
```

**示例输出**:

```json
{
  "content": "# Hawaii News Now\n\n## Latest Headlines\n...",
  "provider": "web-scraper",
  "id": "https://www.hawaiinewsnow.com/",
  "createdAt": "2025-10-27T08:00:00.000Z",
  "type": "webpage",
  "metadata": {
    "sourceURL": "https://www.hawaiinewsnow.com/",
    "title": "Hawaii News Now - Breaking News, Weather, Traffic",
    "author": "Hawaii News Now Team",
    "language": "en"
  }
}
```

---

## 🔐 授权配置（OAuth）

### Nango 授权（推荐）

**优势**: 自动处理所有 OAuth 流程

1. 注册 Nango: https://www.nango.dev/
2. 创建 Integration（Google Drive / GitHub / Notion）
3. 获取 Secret Key 和 Connection ID
4. 在代码中使用：

```typescript
await connector.authorizeNango({
  nango_connection_id: process.env.NANGO_CONNECTION_ID_TEST!,
})
```

### 传统 OAuth 授权

```typescript
// Google Drive
await connector.authorize({
  access_token: 'ya29.a0AfH6SMB...',
  refresh_token: '1//0e...',
  expiry_date: 1640000000000,
})

// GitHub
await connector.authorize({
  access_token: 'ghp_xxxxxxxxxxxx',
})
```

---

## 📊 成本优化策略

### 1. 使用缓存

```typescript
import { LRUCache } from 'lru-cache'

const cache = new LRUCache<string, Document[]>({
  max: 100,
  ttl: 1000 * 60 * 60, // 1 小时
})

async function getCachedDocuments(url: string) {
  const cached = cache.get(url)
  if (cached) {
    console.log('✅ 缓存命中')
    return cached
  }

  const connector = createDataConnector({ provider: 'web-scraper' })
  connector.setOptions({ urls: [url], mode: 'single_urls' })
  const docs = await connector.getDocuments()

  cache.set(url, docs)
  return docs
}
```

### 2. 批量处理

```typescript
// ❌ 坏：逐个爬取
for (const url of urls) {
  const connector = createDataConnector({ provider: 'web-scraper' })
  connector.setOptions({ urls: [url], mode: 'single_urls' })
  await connector.getDocuments()
}

// ✅ 好：批量爬取
const connector = createDataConnector({ provider: 'web-scraper' })
connector.setOptions({ urls: urls, mode: 'single_urls' })
const allDocs = await connector.getDocuments()
```

### 3. 密钥轮换

```typescript
const apiKeys = [
  process.env.FIRECRAWL_API_KEY!,
  process.env.FIRECRAWL_API_KEY_BACKUP_1!,
  process.env.FIRECRAWL_API_KEY_BACKUP_2!,
].filter(Boolean)

let currentKeyIndex = 0

function getNextApiKey() {
  const key = apiKeys[currentKeyIndex]
  currentKeyIndex = (currentKeyIndex + 1) % apiKeys.length
  return key
}
```

---

## 🧪 测试配置

创建 `src/__tests__/connectors.test.ts`:

```typescript
import { describe, it, expect } from '@jest/globals'
import { createDataConnector } from '@mendable/data-connectors'

describe('Web Scraper Connector', () => {
  it('应该成功爬取网页', async () => {
    const connector = createDataConnector({ provider: 'web-scraper' })

    connector.setOptions({
      urls: ['https://example.com'],
      mode: 'single_urls',
    })

    const docs = await connector.getDocuments()

    expect(docs).toHaveLength(1)
    expect(docs[0].content).toContain('Example Domain')
    expect(docs[0].metadata.sourceURL).toBe('https://example.com')
  })

  it('应该处理多个 URL', async () => {
    const connector = createDataConnector({ provider: 'web-scraper' })

    connector.setOptions({
      urls: ['https://example.com', 'https://example.org'],
      mode: 'single_urls',
    })

    const docs = await connector.getDocuments()
    expect(docs.length).toBeGreaterThanOrEqual(2)
  })
})
```

---

## 📚 HawaiiHub 集成示例

创建 `src/hawaiihub-scraper.ts`:

```typescript
import { createDataConnector } from '@mendable/data-connectors'
import * as fs from 'fs/promises'

/**
 * HawaiiHub 新闻爬取器
 *
 * 功能：
 * - 爬取夏威夷主要新闻源
 * - 保存为 LLM-ready Markdown
 * - 自动去重和清洗
 */
async function scrapeHawaiiNews() {
  const newsSourcesconnector = createDataConnector({
    provider: 'web-scraper',
  })

  // 夏威夷新闻源
  const sources = [
    'https://www.hawaiinewsnow.com/',
    'https://www.staradvertiser.com/',
    'https://www.civilbeat.org/',
    'https://www.mauinow.com/',
  ]

  connector.setOptions({
    urls: sources,
    mode: 'single_urls',
  })

  console.log('🔥 开始爬取夏威夷新闻...')
  const documents = await connector.getDocuments()

  console.log(`✅ 成功爬取 ${documents.length} 个页面`)

  // 保存为 Markdown
  const timestamp = new Date().toISOString().split('T')[0]
  const outputDir = `./data/hawaii-news-${timestamp}`

  await fs.mkdir(outputDir, { recursive: true })

  for (const doc of documents) {
    const filename = `${outputDir}/${sanitizeFilename(doc.metadata.sourceURL!)}.md`

    const content = `# ${doc.metadata.title || 'Unknown'}

> **来源**: ${doc.metadata.sourceURL}
> **爬取时间**: ${new Date().toISOString()}
> **提供者**: ${doc.provider}

---

${doc.content}
`

    await fs.writeFile(filename, content, 'utf-8')
    console.log(`💾 已保存: ${filename}`)
  }

  console.log(`\n🎉 完成！数据已保存到 ${outputDir}/`)
}

function sanitizeFilename(url: string): string {
  return url
    .replace(/https?:\/\//, '')
    .replace(/[\/\\?%*:|"<>]/g, '-')
    .substring(0, 100)
}

scrapeHawaiiNews()
```

---

## 🛠️ 项目结构推荐

```
FireShot/
├── .env                          # 环境变量（不提交）
├── .env.template                 # 环境变量模板
├── package.json                  # Node.js 依赖
├── tsconfig.json                 # TypeScript 配置
│
├── src/                          # TypeScript 源代码
│   ├── connectors/               # 连接器封装
│   │   ├── web-scraper.ts
│   │   ├── google-drive.ts
│   │   └── github.ts
│   │
│   ├── scrapers/                 # 爬虫脚本
│   │   ├── hawaiihub-scraper.ts
│   │   └── news-aggregator.ts
│   │
│   ├── utils/                    # 工具函数
│   │   ├── cache.ts
│   │   ├── rate-limiter.ts
│   │   └── error-handler.ts
│   │
│   └── __tests__/                # 测试文件
│       └── connectors.test.ts
│
├── scripts/                      # Python 脚本（已有）
│   ├── scrape_firecrawl_blog.py
│   └── analyze_firecrawl_blog.py
│
├── data/                         # 爬取数据
│   ├── raw/                      # 原始数据
│   ├── processed/                # 处理后数据
│   └── cache/                    # 缓存
│
└── docs/                         # 文档
    ├── FIRECRAWL_ECOSYSTEM_SETUP.md  # 本文件
    └── ...
```

---

## 🚦 快速启动清单

### ✅ 初次配置（30 分钟）

- [ ] 1. 注册 Firecrawl 账号，获取 API Key
- [ ] 2. 创建 `.env` 文件，配置 `FIRECRAWL_API_KEY`
- [ ] 3. 安装 Python SDK: `pip3 install firecrawl-py`
- [ ] 4. 测试 Python SDK: `python3 scripts/scrape_firecrawl_blog.py`
- [ ] 5. （可选）安装 Node.js SDK: `npm install @mendable/data-connectors`
- [ ] 6. （可选）创建 TypeScript 示例并运行

### ✅ 高级配置（可选，+30 分钟）

- [ ] 7. 配置 Nango OAuth（Google Drive/GitHub 集成）
- [ ] 8. 设置 Redis 缓存
- [ ] 9. 配置密钥轮换
- [ ] 10. 编写自动化测试
- [ ] 11. 设置 GitHub Actions CI/CD

---

## 📖 学习资源

### 官方文档

- **完整文档**: https://docs.firecrawl.dev/
- **API 参考**: https://docs.firecrawl.dev/api-reference/introduction
- **示例应用**: https://github.com/firecrawl/firecrawl-app-examples
- **Playground**: https://www.firecrawl.dev/playground

### 教程

- **FreeCodeCamp 教程**: https://www.freecodecamp.org/news/how-to-turn-websites-into-llm-ready-data-using-firecrawl/
- **Blott 开发指南**: https://www.blott.com/blog/post/how-to-build-llm-ready-datasets-with-firecrawl-a-developers-guide
- **LangChain 集成**: https://python.langchain.com/docs/integrations/document_loaders/firecrawl/

### 视频

- **YouTube 教程**: https://www.youtube.com/watch?v=qk1iQKHaKiI

---

## 🆘 故障排除

### 问题 1: API Key 无效

```bash
错误: {"error": "Invalid API Key"}

解决:
1. 检查 .env 文件中的 FIRECRAWL_API_KEY
2. 确认密钥格式：fc-xxxxxxxxxxxxxxxxxxxxxxxx
3. 在 Dashboard 中重新生成密钥
```

### 问题 2: 安装 data-connectors 失败

```bash
错误: npm ERR! code ERESOLVE

解决:
npm install @mendable/data-connectors --legacy-peer-deps
```

### 问题 3: TypeScript 编译错误

```bash
错误: Cannot find module '@mendable/data-connectors'

解决:
1. 确认已安装：npm list @mendable/data-connectors
2. 检查 tsconfig.json 中的 moduleResolution: "node"
3. 删除 node_modules 重新安装：
   rm -rf node_modules package-lock.json
   npm install
```

### 问题 4: OAuth 授权失败

```bash
错误: Authorization failed

解决:
1. 使用 Nango（推荐）：自动处理 OAuth
2. 手动授权：
   - Google Drive: 需要 Client ID + Secret + Redirect URI
   - GitHub: 需要 Personal Access Token
```

---

## 🎯 下一步

### 立即行动

1. ✅ **5 分钟**: 注册 Firecrawl，获取 API Key
2. ✅ **10 分钟**: 安装 Python SDK，运行第一个爬虫
3. ✅ **15 分钟**: 安装 data-connectors，测试 Web Scraper

### 本周目标

4. 🎯 集成 Google Drive 连接器（用于 HawaiiHub 文档管理）
5. 🎯 创建夏威夷新闻自动爬取脚本
6. 🎯 实现 Redis 缓存（节省 50% 成本）

### 本月目标

7. 🚀 部署自动化新闻采集系统
8. 🚀 集成 Notion（用于内容管理）
9. 🚀 配置 GitHub Actions（定时爬取）

---

**配置完成后**，阅读以下文档：

- `FIRECRAWL_CLOUD_API_RULES.md` - API 使用规范
- `FIRECRAWL_BLOG_SCRAPING_SUMMARY.md` - 实战案例
- `FIRECRAWL_GLOSSARY_COMPLETE.md` - 术语表

---

**版本**: v1.0
**维护者**: HawaiiHub AI Team
**最后更新**: 2025-10-27
**License**: MIT
