# FireShot AI åŠ©æ‰‹è§„èŒƒ

**ç‰ˆæœ¬**: v1.0.0
**æ›´æ–°æ—¶é—´**: 2025-10-28
**é€‚ç”¨èŒƒå›´**: æ‰€æœ‰ AI ç¼–ç åŠ©æ‰‹ï¼ˆCursorã€Claude Codeã€CodeBuddy ç­‰ï¼‰

---

## ğŸŒ æ ¸å¿ƒåŸåˆ™

### è¯­è¨€è¦æ±‚

- **æ‰€æœ‰è¾“å‡ºå¿…é¡»ä½¿ç”¨ç®€ä½“ä¸­æ–‡**ï¼ˆä»£ç æ³¨é‡Šã€æ–‡æ¡£ã€æ—¥å¿—ã€æç¤ºä¿¡æ¯ï¼‰
- è‹±æ–‡ä»…ç”¨äºï¼šä»£ç å˜é‡åã€å‡½æ•°åã€ç±»åã€åŒ…å
- æŠ€æœ¯æœ¯è¯­å¯ä¿ç•™è‹±æ–‡ï¼ˆå¦‚ Firecrawlã€MCPã€APIï¼‰

### é¡¹ç›®å®šä½

- **é¡¹ç›®åç§°**: FireShot
- **æ ¸å¿ƒä½¿å‘½**: Firecrawl äº‘ API æœ€ä½³å®è·µ + HawaiiHub æ•°æ®é‡‡é›†
- **æŠ€æœ¯æ ˆ**: Python 3.14 + Firecrawl SDK v2 + MCP å·¥å…·é“¾
- **å›¢é˜Ÿæ¨¡å¼**: AI å›¢é˜Ÿåä½œï¼ˆå¤š Agent å¹¶è¡Œï¼‰

---

## ğŸ“‹ OpenSpec å·¥ä½œæµ

### 1. åˆ›å»ºå˜æ›´ææ¡ˆ

å½“ç”¨æˆ·æå‡ºæ–°åŠŸèƒ½æˆ–æ”¹è¿›éœ€æ±‚æ—¶ï¼š

```
ç”¨æˆ·: æ·»åŠ å¤å¨å¤·ç§Ÿæˆ¿ä¿¡æ¯çˆ¬è™«

AI: æˆ‘ä¼šä¸ºæ‚¨åˆ›å»º OpenSpec å˜æ›´ææ¡ˆã€‚
    *åˆ›å»º openspec/changes/add-rental-scraper/ ç›®å½•*
    *ç”Ÿæˆ proposal.md, tasks.md, specs/ ç­‰æ–‡ä»¶*
```

**Slash å‘½ä»¤å¿«æ·æ–¹å¼**ï¼ˆCursor/Claude Code/CodeBuddyï¼‰:

```
/openspec:proposal æ·»åŠ å¤å¨å¤·ç§Ÿæˆ¿ä¿¡æ¯çˆ¬è™«
```

### 2. éªŒè¯å’Œå®¡æŸ¥

åœ¨å®æ–½å‰æ£€æŸ¥è§„èŒƒï¼š

```bash
openspec list                        # æŸ¥çœ‹æ´»åŠ¨å˜æ›´
openspec validate add-rental-scraper # éªŒè¯æ ¼å¼
openspec show add-rental-scraper     # æŸ¥çœ‹è¯¦æƒ…
```

### 3. å®æ–½å˜æ›´

```
ç”¨æˆ·: è§„èŒƒçœ‹èµ·æ¥ä¸é”™ï¼Œå¼€å§‹å®æ–½å§

AI: æˆ‘ä¼šæŒ‰ç…§ä»»åŠ¡æ¸…å•å®æ–½ add-rental-scraper å˜æ›´ã€‚
    *ä» openspec/changes/add-rental-scraper/tasks.md è¯»å–ä»»åŠ¡*
    *é€ä¸ªå®æ–½å¹¶æ ‡è®°å®ŒæˆçŠ¶æ€*
```

**Slash å‘½ä»¤å¿«æ·æ–¹å¼**:

```
/openspec:apply add-rental-scraper
```

### 4. å½’æ¡£å®Œæˆçš„å˜æ›´

```
ç”¨æˆ·: è¯·å½’æ¡£è¿™ä¸ªå˜æ›´

AI: æˆ‘ä¼šå½’æ¡£ add-rental-scraper å˜æ›´ã€‚
    *è¿è¡Œ: openspec archive add-rental-scraper --yes*
    *æ›´æ–°è§„èŒƒåˆ° openspec/specs/*
    *ç§»åŠ¨å˜æ›´æ–‡ä»¶åˆ° openspec/archive/*
```

**Slash å‘½ä»¤å¿«æ·æ–¹å¼**:

```
/openspec:archive add-rental-scraper
```

---

## ğŸ”¥ Firecrawl ä½¿ç”¨è§„èŒƒ

### å·¥å…·é€‰æ‹©å†³ç­–æ ‘

```python
# âœ… P0: MCP å·¥å…·ï¼ˆæœ€ç®€å•ã€æœ€å¯é ï¼‰
result = mcp_firecrawl_firecrawl_scrape(
    url="https://example.com",
    formats=["markdown"],
    onlyMainContent=True  # âš ï¸ MCP å·¥å…·ä½¿ç”¨é©¼å³°å¼
)

# âœ… P1: Python SDK v2ï¼ˆéœ€è¦æ›´å¤šæ§åˆ¶æ—¶ï¼‰
from firecrawl import FirecrawlApp
app = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))
result = app.scrape(
    url="https://example.com",
    formats=["markdown"],
    only_main_content=True  # âš ï¸ SDK ä½¿ç”¨ä¸‹åˆ’çº¿
)
# è®¿é—®ç»“æœï¼šresult.markdownï¼ˆå±æ€§ï¼‰ï¼Œä¸æ˜¯ result.get("markdown")

# âŒ é¿å…: ç›´æ¥ä½¿ç”¨ requests + BeautifulSoup
```

**é€‰æ‹©è§„åˆ™**:

- å¤æ‚é¡µé¢ï¼ˆJSã€åŠ¨æ€åŠ è½½ï¼‰â†’ **MCP å·¥å…·**
- æ‰¹é‡çˆ¬å–ï¼ˆå·²çŸ¥ URLï¼‰â†’ **Python SDK batch_scrape**
- æ•´ç«™çˆ¬å– â†’ **Python SDK crawl**
- æœç´¢ + çˆ¬å– â†’ **Python SDK search**

### å¿…é¡»éµå®ˆçš„é…ç½®è§„èŒƒ

```python
# âœ… æ­£ç¡®ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡
import os
from dotenv import load_dotenv

load_dotenv()
api_key = os.getenv("FIRECRAWL_API_KEY")

# âŒ é”™è¯¯ï¼šç¡¬ç¼–ç  API å¯†é’¥
api_key = "fc-xxxx"  # æ°¸è¿œä¸è¦è¿™æ ·åšï¼
```

### é”™è¯¯å¤„ç†æ¨¡å¼ï¼ˆå¼ºåˆ¶ï¼‰

```python
def safe_scrape(url: str, max_retries: int = 3) -> Optional[dict]:
    """
    å®‰å…¨çˆ¬å–ï¼Œå¸¦é‡è¯•å’Œæ—¥å¿—

    Args:
        url: è¦çˆ¬å–çš„ URL
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°

    Returns:
        çˆ¬å–ç»“æœå­—å…¸ï¼Œå¤±è´¥è¿”å› None
    """
    for attempt in range(max_retries):
        try:
            result = app.scrape(url, formats=["markdown"], only_main_content=True)

            if not result or not hasattr(result, "markdown"):
                raise ValueError("è¿”å›ç»“æœæ— æ•ˆ")

            logging.info(f"æˆåŠŸçˆ¬å–: {url}")
            return result

        except RequestTimeoutError as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt  # æŒ‡æ•°é€€é¿
                logging.warning(f"è¶…æ—¶ï¼Œ{wait_time}ç§’åé‡è¯•... ({attempt+1}/{max_retries})")
                time.sleep(wait_time)
            else:
                logging.error(f"å¤±è´¥ï¼ˆ{max_retries}æ¬¡é‡è¯•åï¼‰: {url} - {e}")
                return None
        except Exception as e:
            logging.error(f"æœªçŸ¥é”™è¯¯: {url} - {e}")
            return None
```

### æ€§èƒ½ä¼˜åŒ–ï¼ˆå¿…é¡»ï¼‰

```python
# âœ… ä½¿ç”¨ç¼“å­˜ï¼ˆèŠ‚çœæˆæœ¬ 50%+ï¼‰
result = app.scrape(
    url="https://example.com",
    formats=["markdown"],
    only_main_content=True,
    max_age=172800000  # 2å¤©ç¼“å­˜
)

# âœ… æ‰¹é‡çˆ¬å–ï¼ˆæ›´é«˜æ•ˆï¼‰
urls = ["url1", "url2", "url3"]
results = app.batch_scrape(urls, formats=["markdown"])

# âŒ é”™è¯¯ï¼šé€ä¸ªçˆ¬å–ï¼ˆæ…¢ + è´µï¼‰
for url in urls:
    result = app.scrape(url)  # ä¸²è¡Œå¤„ç†
```

---

## ğŸ Python ä»£ç è§„èŒƒ

### ç±»å‹æ³¨è§£ï¼ˆå¼ºåˆ¶ï¼‰

```python
from typing import Optional, Dict, List

def scrape_news(
    url: str,
    formats: List[str] = ["markdown"],
    timeout: int = 60
) -> Optional[Dict[str, str]]:
    """
    çˆ¬å–æ–°é—»å†…å®¹

    Args:
        url: æ–°é—» URL
        formats: è¿”å›æ ¼å¼åˆ—è¡¨
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰

    Returns:
        åŒ…å« markdownã€html ç­‰å†…å®¹çš„å­—å…¸ï¼Œå¤±è´¥è¿”å› None
    """
    # ... å®ç°
    return {"markdown": content}
```

### æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆå¼ºåˆ¶ï¼Œä¸­æ–‡ï¼‰

```python
def analyze_articles(articles: List[Dict]) -> Dict[str, int]:
    """
    åˆ†ææ–‡ç« æ•°æ®ç»Ÿè®¡ä¿¡æ¯

    ç»Ÿè®¡å†…å®¹ï¼š
    - ä½œè€…åˆ†å¸ƒ
    - å‘å¸ƒæ—¶é—´åˆ†å¸ƒ
    - çƒ­é—¨å…³é”®è¯

    Args:
        articles: æ–‡ç« åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ç« åŒ…å« titleã€authorã€date ç­‰å­—æ®µ

    Returns:
        ç»Ÿè®¡ç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
        - total_articles: æ€»æ–‡ç« æ•°
        - authors: ä½œè€…ç»Ÿè®¡ {ä½œè€…å: æ–‡ç« æ•°}
        - keywords: å…³é”®è¯ç»Ÿè®¡ {å…³é”®è¯: å‡ºç°æ¬¡æ•°}

    Example:
        >>> articles = [{"title": "æµ‹è¯•", "author": "å¼ ä¸‰", "date": "2025-10-27"}]
        >>> stats = analyze_articles(articles)
        >>> print(stats["total_articles"])
        1
    """
    # ... å®ç°
```

### ä»£ç é£æ ¼ï¼ˆåŸºäº Ruffï¼‰

```python
# âœ… ä½¿ç”¨åŒå¼•å·ï¼ˆé¡¹ç›®æ ‡å‡†ï¼‰
message = "çˆ¬å–æˆåŠŸ"
url = "https://example.com"

# âœ… å¯¼å…¥é¡ºåºï¼šæ ‡å‡†åº“ â†’ ç¬¬ä¸‰æ–¹åº“ â†’ æœ¬åœ°æ¨¡å—
import json
import re
from datetime import datetime

from firecrawl import FirecrawlApp
from dotenv import load_dotenv

from .utils import parse_date
from .config import FIRECRAWL_API_KEY

# âœ… å‘½åè§„èŒƒ
class ArticleScraper:  # ç±»åï¼šå¤§é©¼å³°
    def __init__(self):
        self.api_key = ""  # å®ä¾‹å˜é‡ï¼šsnake_case

    def scrape_article(self) -> str:  # æ–¹æ³•åï¼šsnake_case
        return ""

FIRECRAWL_API_URL = "https://api.firecrawl.dev"  # å¸¸é‡ï¼šå¤§å†™+ä¸‹åˆ’çº¿
```

---

## ğŸ“Š æ•°æ®å¤„ç†è§„èŒƒ

### ä¿å­˜æ ¼å¼ï¼ˆå¿…é¡» 3 ç§ï¼‰

```python
def save_scraped_data(content: str, metadata: Dict) -> None:
    """
    ä¿å­˜çˆ¬å–çš„æ•°æ®åˆ°å¤šç§æ ¼å¼
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # 1. åŸå§‹ Markdownï¼ˆäººç±»å¯è¯»ï¼‰
    with open(f"raw_{timestamp}.md", "w", encoding="utf-8") as f:
        f.write(f"# çˆ¬å–æ•°æ®\n\n")
        f.write(f"> æ—¶é—´: {datetime.now()}\n\n")
        f.write(content)

    # 2. ç»“æ„åŒ– JSONï¼ˆç¨‹åºå¤„ç†ï¼‰
    with open(f"data_{timestamp}.json", "w", encoding="utf-8") as f:
        json.dump({
            "content": content,
            "metadata": metadata,
            "scraped_at": datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2)

    # 3. CSVï¼ˆåˆ†æå·¥å…·ï¼‰
    # ... CSV å¯¼å‡ºé€»è¾‘
```

### æ•°æ®éªŒè¯

```python
from pydantic import BaseModel, HttpUrl, Field

class Article(BaseModel):
    """æ–‡ç« æ•°æ®æ¨¡å‹"""
    title: str = Field(..., min_length=1, max_length=200)
    url: HttpUrl
    author: str
    date: str  # ISO 8601 æ ¼å¼
    content: Optional[str] = None
```

---

## ğŸ’° æˆæœ¬æ§åˆ¶è§„èŒƒ

### è¯·æ±‚è®¡æ•°å’Œé¢„ç®—ç›‘æ§

```python
class FirecrawlClient:
    """Firecrawl å®¢æˆ·ç«¯ï¼ˆå¸¦æˆæœ¬æ§åˆ¶ï¼‰"""

    def __init__(self, api_key: str, daily_budget: float = 10.0):
        self.app = FirecrawlApp(api_key=api_key)
        self.daily_budget = daily_budget
        self.request_count = 0
        self.total_cost = 0.0

    def scrape(self, url: str, **kwargs) -> dict:
        """çˆ¬å–å¹¶è®°å½•æˆæœ¬"""
        # æ£€æŸ¥é¢„ç®—
        if self.total_cost >= self.daily_budget:
            raise BudgetExceededError(f"è¶…å‡ºæ¯æ—¥é¢„ç®—: ${self.daily_budget}")

        # æ‰§è¡Œçˆ¬å–
        result = self.app.scrape(url, **kwargs)

        # è®°å½•æˆæœ¬ï¼ˆå‡è®¾ $0.01/è¯·æ±‚ï¼‰
        cost = 0.01
        self.request_count += 1
        self.total_cost += cost

        logging.info(
            f"è¯·æ±‚ #{self.request_count} | "
            f"æˆæœ¬: ${cost:.4f} | "
            f"ç´¯è®¡: ${self.total_cost:.2f}/{self.daily_budget}"
        )

        return result
```

---

## ğŸ“ Git æäº¤è§„èŒƒ

### Conventional Commitsï¼ˆå¼ºåˆ¶ï¼‰

```bash
# âœ… æ­£ç¡®çš„æäº¤æ¶ˆæ¯
git commit -m "feat(scraper): æ·»åŠ  Firecrawl MCP å·¥å…·æ”¯æŒ"
git commit -m "fix(parser): ä¿®å¤æ–‡ç« æ—¥æœŸè§£æé”™è¯¯"
git commit -m "docs(api): æ›´æ–° API å¯†é’¥é…ç½®æŒ‡å—"
git commit -m "refactor(storage): ä¼˜åŒ–æ•°æ®å­˜å‚¨æ ¼å¼"
git commit -m "perf(cache): å®ç° Redis ç¼“å­˜ï¼ŒèŠ‚çœ 50% æˆæœ¬"

# âŒ é”™è¯¯çš„æäº¤æ¶ˆæ¯
git commit -m "æ›´æ–°ä»£ç "
git commit -m "fix bug"
```

**ç±»å‹æ¸…å•**:

- `feat`: æ–°åŠŸèƒ½
- `fix`: Bug ä¿®å¤
- `docs`: æ–‡æ¡£æ›´æ–°
- `refactor`: ä»£ç é‡æ„
- `perf`: æ€§èƒ½ä¼˜åŒ–
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: æ„å»º/å·¥å…·é“¾
- `style`: ä»£ç æ ¼å¼

---

## âš ï¸ ç¦æ­¢äº‹é¡¹

### ç»å¯¹ç¦æ­¢ âŒ

1. ç¡¬ç¼–ç  API å¯†é’¥åˆ°ä»£ç ä¸­
2. æäº¤ `.env` æ–‡ä»¶åˆ° Git
3. è·³è¿‡é”™è¯¯å¤„ç†ï¼ˆæ‰€æœ‰å¤–éƒ¨è°ƒç”¨å¿…é¡» try-exceptï¼‰
4. æ— é™é‡è¯•ï¼ˆå¿…é¡»è®¾ç½® max_retriesï¼‰
5. å¿½ç•¥æˆæœ¬ç›‘æ§ï¼ˆå¿…é¡»è®°å½•æ¯æ¬¡ API è°ƒç”¨ï¼‰
6. ä½¿ç”¨å•å¼•å·ï¼ˆPython ç»Ÿä¸€åŒå¼•å·ï¼‰
7. ç¼ºå°‘ç±»å‹æ³¨è§£ï¼ˆæ‰€æœ‰å‡½æ•°å¿…é¡»æœ‰å®Œæ•´ç±»å‹ï¼‰
8. ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆæ‰€æœ‰å…¬å¼€å‡½æ•°/ç±»å¿…é¡»æœ‰ docstringï¼‰

### å¼ºçƒˆä¸æ¨è âš ï¸

1. ä¸æ£€æŸ¥ç¼“å­˜ç›´æ¥çˆ¬å–ï¼ˆæµªè´¹æˆæœ¬ï¼‰
2. ä¸²è¡Œå¤„ç†å¤§é‡ URLï¼ˆä½¿ç”¨ batch_scrapeï¼‰
3. ä¸è®°å½•æ—¥å¿—ï¼ˆéš¾ä»¥è°ƒè¯•ï¼‰
4. ä¸éªŒè¯æ•°æ®æ ¼å¼ï¼ˆä½¿ç”¨ Pydanticï¼‰

---

## ğŸ“š å¿«é€Ÿå‚è€ƒ

### OpenSpec å‘½ä»¤

```bash
openspec list                  # æŸ¥çœ‹æ´»åŠ¨å˜æ›´
openspec view                  # äº¤äº’å¼ä»ªè¡¨æ¿
openspec show <change>         # æŸ¥çœ‹å˜æ›´è¯¦æƒ…
openspec validate <change>     # éªŒè¯è§„èŒƒæ ¼å¼
openspec archive <change> -y   # å½’æ¡£å®Œæˆçš„å˜æ›´
```

### Firecrawl SDK v2 å…³é”®ç‰¹æ€§

- å‘½åçº¦å®šï¼šä¸‹åˆ’çº¿ `only_main_content=True`ï¼ˆéé©¼å³°ï¼‰
- è¿”å›ç±»å‹ï¼šDocument å¯¹è±¡ `result.markdown`ï¼ˆéå­—å…¸ï¼‰
- é»˜è®¤ç¼“å­˜ï¼š`max_age=172800000`ï¼ˆ2å¤©ï¼‰

### ç¯å¢ƒå˜é‡

```bash
# å¿…éœ€
FIRECRAWL_API_KEY=fc-xxx

# æ¨èï¼ˆå¯†é’¥è½®æ¢ï¼‰
FIRECRAWL_API_KEY_BACKUP_1=fc-xxx
FIRECRAWL_API_KEY_BACKUP_2=fc-xxx
FIRECRAWL_API_KEY_BACKUP_3=fc-xxx

# æˆæœ¬æ§åˆ¶
FIRECRAWL_DAILY_BUDGET=10.0
FIRECRAWL_TIMEOUT=60
```

---

## ğŸ“– å‚è€ƒæ–‡æ¡£

### æ ¸å¿ƒæ–‡æ¡£

- **OpenSpec é¡¹ç›®è§„èŒƒ**: `openspec/project.md`
- **SDK é…ç½®æ€»ç»“**: `SDK_CONFIGURATION_COMPLETE.md`
- **å¿«é€Ÿå‚è€ƒ**: `QUICK_REFERENCE.md`
- **æ€§èƒ½ä¼˜åŒ–æŠ¥å‘Š**: `CURSOR_æ€§èƒ½ä¼˜åŒ–å®ŒæˆæŠ¥å‘Š_2025-10-28.md`

### å­¦ä¹ èµ„æº

- **Firecrawl å­¦ä¹ æ‰‹å†Œ**: `Firecrawlå­¦ä¹ æ‰‹å†Œ/` ç›®å½•
- **æ¨¡æ¿åº“**: `FIRECRAWL_TEMPLATES_CATALOG.md`ï¼ˆ55ä¸ªæ¨¡æ¿ï¼‰
- **æ•°æ®æºç›®å½•**: `HAWAIIHUB_DATA_SOURCES_CATALOG.md`

### åœ¨çº¿èµ„æº

- OpenSpec å®˜ç½‘: https://openspec.dev/
- Firecrawl æ–‡æ¡£: https://docs.firecrawl.dev/
- NewsAPI æ–‡æ¡£: https://newsapi.org/docs

---

**ç»´æŠ¤è€…**: HawaiiHub AI Team
**ç‰ˆæœ¬**: v1.0.0
**æœ€åæ›´æ–°**: 2025-10-28
