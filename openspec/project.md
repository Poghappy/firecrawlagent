# FireShot é¡¹ç›®è§„èŒƒ

## é¡¹ç›®æ¦‚è¿°

**é¡¹ç›®åç§°**: FireShot
**é¡¹ç›®å®šä½**: Firecrawl äº‘ API æœ€ä½³å®è·µå’Œ HawaiiHub æ•°æ®é‡‡é›†å¹³å°
**æŠ€æœ¯æ ˆ**: Python 3.14 + Firecrawl SDK v2 + MCP å·¥å…·é“¾
**å›¢é˜Ÿè§„æ¨¡**: AI å›¢é˜Ÿï¼ˆå¤š Agent åä½œï¼‰
**æ›´æ–°æ—¶é—´**: 2025-10-28

---

## æ ¸å¿ƒèƒ½åŠ›

### 1. æ•°æ®é‡‡é›†å¼•æ“

- **Firecrawl Cloud API**: æ™ºèƒ½ç½‘é¡µçˆ¬å–ã€æ‰¹é‡é‡‡é›†ã€æœç´¢é›†æˆ
- **NewsAPI é›†æˆ**: 150,000+ å…¨çƒæ–°é—»æºå®æ—¶å¤´æ¡
- **Steel Browser**: äº‘ç«¯æµè§ˆå™¨è‡ªåŠ¨åŒ–
- **Playwright MCP**: æœ¬åœ°æµè§ˆå™¨äº¤äº’

### 2. HawaiiHub æ•°æ®æº

- ç§Ÿæˆ¿ä¿¡æ¯ï¼ˆCraigslist Hawaiiï¼‰
- é¤å…æ•°æ®ï¼ˆYelpã€æœ¬åœ°åäººé¤å…ï¼‰
- æœ¬åœ°æ–°é—»ï¼ˆHawaii News Nowã€Star Advertiserï¼‰
- å•†å®¶ä¿¡æ¯ï¼ˆåˆ†ç±»ä¿¡æ¯ç½‘ç«™ï¼‰
- ç¤¾åŒºåŠ¨æ€ï¼ˆåäººç¤¾åŒºå¹³å°ï¼‰

### 3. å¼€å‘å·¥å…·é“¾

- **MCP æœåŠ¡å™¨**: Firecrawlã€GitHubã€filesystemã€Playwright
- **Cursor AI**: ä¸»å¼€å‘ç¯å¢ƒ
- **OpenSpec**: è§„èŒƒé©±åŠ¨å¼€å‘æ¡†æ¶

---

## æŠ€æœ¯è§„èŒƒ

### Python ä»£ç æ ‡å‡†

#### ç±»å‹æ³¨è§£ï¼ˆå¼ºåˆ¶ï¼‰

```python
from typing import Optional, Dict, List

def scrape_news(
    url: str,
    formats: List[str] = ["markdown"],
    timeout: int = 60
) -> Optional[Dict[str, str]]:
    """
    çˆ¬å–æ–°é—»å†…å®¹ï¼ˆå¿…é¡»æœ‰ç±»å‹æ³¨è§£å’Œä¸­æ–‡ docstringï¼‰
    """
    pass
```

#### å‘½åçº¦å®š

- **Firecrawl SDK v2**: ä½¿ç”¨ä¸‹åˆ’çº¿ `only_main_content=True`ï¼ˆéé©¼å³°ï¼‰
- **è¿”å›å€¼**: Document å¯¹è±¡ `result.markdown`ï¼ˆéå­—å…¸ï¼‰
- **ç¯å¢ƒå˜é‡**: å¤§å†™ä¸‹åˆ’çº¿ `FIRECRAWL_API_KEY`

#### å·¥å…·é“¾

- **æ ¼å¼åŒ–**: Ruffï¼ˆæ›¿ä»£ Blackï¼‰
- **ç±»å‹æ£€æŸ¥**: mypy --strict
- **æµ‹è¯•**: pytestï¼ˆä¸ä½¿ç”¨ unittestï¼‰
- **ä¾èµ–ç®¡ç†**: pip + requirements.txt

### Firecrawl ä½¿ç”¨è§„èŒƒ

#### å·¥å…·é€‰æ‹©ä¼˜å…ˆçº§

```python
# P0: MCP å·¥å…·ï¼ˆæœ€ç®€å•ï¼‰
result = mcp_firecrawl_firecrawl_scrape(
    url="https://example.com",
    formats=["markdown"],
    onlyMainContent=True  # âš ï¸ MCP ä½¿ç”¨é©¼å³°
)

# P1: Python SDKï¼ˆéœ€è¦æ›´å¤šæ§åˆ¶ï¼‰
from firecrawl import FirecrawlApp
app = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))
result = app.scrape(
    url="https://example.com",
    formats=["markdown"],
    only_main_content=True  # âš ï¸ SDK ä½¿ç”¨ä¸‹åˆ’çº¿
)
```

#### æˆæœ¬æ§åˆ¶

- **ç¼“å­˜ç­–ç•¥**: `max_age=172800000`ï¼ˆ2å¤©ï¼‰èŠ‚çœ 50%+ æˆæœ¬
- **æ‰¹é‡å¤„ç†**: ä½¿ç”¨ `batch_scrape()` è€Œéå¾ªç¯
- **å¯†é’¥è½®æ¢**: 4ä¸ª API å¯†é’¥æ”¯æŒè´Ÿè½½å‡è¡¡
- **æ¯æ—¥é¢„ç®—**: $10ï¼ˆç¯å¢ƒå˜é‡ `FIRECRAWL_DAILY_BUDGET`ï¼‰

### é”™è¯¯å¤„ç†æ¨¡å¼ï¼ˆå¼ºåˆ¶ï¼‰

```python
def safe_scrape(url: str, max_retries: int = 3) -> Optional[dict]:
    """
    å®‰å…¨çˆ¬å–ï¼Œå¸¦é‡è¯•å’Œæ—¥å¿—
    """
    for attempt in range(max_retries):
        try:
            result = app.scrape(url, formats=["markdown"], only_main_content=True)

            if not result or not hasattr(result, "markdown"):
                raise ValueError("è¿”å›ç»“æœæ— æ•ˆ")

            logging.info(f"æˆåŠŸçˆ¬å–: {url}")
            return result

        except RequestTimeoutError as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                logging.warning(f"è¶…æ—¶ï¼Œ{wait_time}ç§’åé‡è¯•...")
                time.sleep(wait_time)
            else:
                logging.error(f"å¤±è´¥ï¼ˆ{max_retries}æ¬¡é‡è¯•åï¼‰: {url}")
                return None
        except Exception as e:
            logging.error(f"æœªçŸ¥é”™è¯¯: {url} - {e}")
            return None
```

---

## é¡¹ç›®ç»“æ„çº¦å®š

```
FireShot/
â”œâ”€â”€ openspec/                    # ğŸ“‹ OpenSpec è§„èŒƒï¼ˆæœ¬ç›®å½•ï¼‰
â”‚   â”œâ”€â”€ project.md              # é¡¹ç›®æ€»è§„èŒƒ
â”‚   â”œâ”€â”€ specs/                  # å½“å‰è§„èŒƒ
â”‚   â”œâ”€â”€ changes/                # å¾…å®æ–½å˜æ›´
â”‚   â””â”€â”€ archive/                # å·²å½’æ¡£å˜æ›´
â”‚
â”œâ”€â”€ scripts/                     # ğŸ› ï¸ å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ hawaiihub_scraper.py    # HawaiiHub çˆ¬è™«
â”‚   â”œâ”€â”€ test_api_keys.py        # API å¯†é’¥æµ‹è¯•
â”‚   â””â”€â”€ performance_maintenance.sh
â”‚
â”œâ”€â”€ templates/                   # ğŸ“¦ ä»£ç æ¨¡æ¿
â”‚   â”œâ”€â”€ hawaiihub/              # HawaiiHub ä¸“ç”¨æ¨¡æ¿
â”‚   â””â”€â”€ python/                 # Python é€šç”¨æ¨¡æ¿
â”‚
â”œâ”€â”€ data/                        # ğŸ“Š æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ raw/                    # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ processed/              # å¤„ç†åæ•°æ®
â”‚   â””â”€â”€ cache/                  # ç¼“å­˜
â”‚
â”œâ”€â”€ docs/                        # ğŸ“š æ–‡æ¡£
â”‚   â”œâ”€â”€ guides/                 # ä½¿ç”¨æŒ‡å—
â”‚   â”œâ”€â”€ reports/                # é¡¹ç›®æŠ¥å‘Š
â”‚   â””â”€â”€ cursor-guides/          # Cursor ä¸“ç”¨æŒ‡å—
â”‚
â””â”€â”€ Firecrawlå­¦ä¹ æ‰‹å†Œ/           # ğŸ“ Firecrawl åŸ¹è®­èµ„æ–™
```

---

## Git æäº¤è§„èŒƒ

### Conventional Commitsï¼ˆå¼ºåˆ¶ï¼‰

```bash
# âœ… æ­£ç¡®æ ¼å¼
git commit -m "feat(scraper): æ·»åŠ  Firecrawl MCP å·¥å…·æ”¯æŒ"
git commit -m "fix(parser): ä¿®å¤æ–‡ç« æ—¥æœŸè§£æé”™è¯¯"
git commit -m "docs(api): æ›´æ–° API å¯†é’¥é…ç½®æŒ‡å—"
git commit -m "refactor(storage): ä¼˜åŒ–æ•°æ®å­˜å‚¨æ ¼å¼"
git commit -m "perf(cache): å®ç° Redis ç¼“å­˜ï¼ŒèŠ‚çœ 50% æˆæœ¬"

# âŒ é”™è¯¯æ ¼å¼
git commit -m "æ›´æ–°ä»£ç "
git commit -m "fix bug"
```

### ç±»å‹æ¸…å•

- `feat`: æ–°åŠŸèƒ½
- `fix`: Bug ä¿®å¤
- `docs`: æ–‡æ¡£æ›´æ–°
- `refactor`: ä»£ç é‡æ„
- `perf`: æ€§èƒ½ä¼˜åŒ–
- `test`: æµ‹è¯•ç›¸å…³
- `chore`: æ„å»º/å·¥å…·é“¾
- `style`: ä»£ç æ ¼å¼

---

## æ•°æ®å¤„ç†è§„èŒƒ

### ä¿å­˜æ ¼å¼ï¼ˆå¿…é¡» 3 ç§ï¼‰

```python
def save_scraped_data(content: str, metadata: Dict) -> None:
    """
    ä¿å­˜çˆ¬å–æ•°æ®åˆ°å¤šç§æ ¼å¼ï¼ˆä¸‰è§’äº’éªŒï¼‰
    """
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # 1. åŸå§‹ Markdownï¼ˆäººç±»å¯è¯»ï¼‰
    with open(f"raw_{timestamp}.md", "w", encoding="utf-8") as f:
        f.write(f"# çˆ¬å–æ•°æ®\n\n")
        f.write(f"> æ—¶é—´: {datetime.now()}\n\n")
        f.write(content)

    # 2. ç»“æ„åŒ– JSONï¼ˆç¨‹åºå¤„ç†ï¼‰
    with open(f"data_{timestamp}.json", "w", encoding="utf-8") as f:
        json.dump({
            "content": content,
            "metadata": metadata,
            "scraped_at": datetime.now().isoformat()
        }, f, ensure_ascii=False, indent=2)

    # 3. CSVï¼ˆåˆ†æå·¥å…·ï¼‰
    # ... CSV å¯¼å‡ºé€»è¾‘
```

### æ•°æ®éªŒè¯ï¼ˆä½¿ç”¨ Pydanticï¼‰

```python
from pydantic import BaseModel, HttpUrl, Field

class Article(BaseModel):
    """æ–‡ç« æ•°æ®æ¨¡å‹"""
    title: str = Field(..., min_length=1, max_length=200)
    url: HttpUrl
    author: str
    date: str  # ISO 8601 æ ¼å¼
    content: Optional[str] = None
```

---

## ç¦æ­¢äº‹é¡¹

### ç»å¯¹ç¦æ­¢ âŒ

1. ç¡¬ç¼–ç  API å¯†é’¥åˆ°ä»£ç ä¸­
2. æäº¤ `.env` æ–‡ä»¶åˆ° Git
3. è·³è¿‡é”™è¯¯å¤„ç†ï¼ˆæ‰€æœ‰å¤–éƒ¨è°ƒç”¨å¿…é¡» try-exceptï¼‰
4. æ— é™é‡è¯•ï¼ˆå¿…é¡»è®¾ç½® max_retriesï¼‰
5. å¿½ç•¥æˆæœ¬ç›‘æ§ï¼ˆå¿…é¡»è®°å½•æ¯æ¬¡ API è°ƒç”¨ï¼‰
6. ä½¿ç”¨å•å¼•å·ï¼ˆPython ç»Ÿä¸€åŒå¼•å·ï¼‰
7. ç¼ºå°‘ç±»å‹æ³¨è§£ï¼ˆæ‰€æœ‰å‡½æ•°å¿…é¡»æœ‰å®Œæ•´ç±»å‹ï¼‰
8. ç¼ºå°‘æ–‡æ¡£å­—ç¬¦ä¸²ï¼ˆæ‰€æœ‰å…¬å¼€å‡½æ•°/ç±»å¿…é¡»æœ‰ docstringï¼‰

### å¼ºçƒˆä¸æ¨è âš ï¸

1. ä¸æ£€æŸ¥ç¼“å­˜ç›´æ¥çˆ¬å–ï¼ˆæµªè´¹æˆæœ¬ï¼‰
2. ä¸²è¡Œå¤„ç†å¤§é‡ URLï¼ˆä½¿ç”¨ batch_scrapeï¼‰
3. ä¸è®°å½•æ—¥å¿—ï¼ˆéš¾ä»¥è°ƒè¯•ï¼‰
4. ä¸éªŒè¯æ•°æ®æ ¼å¼ï¼ˆä½¿ç”¨ Pydanticï¼‰

---

## ç¯å¢ƒé…ç½®

### å¿…éœ€ç¯å¢ƒå˜é‡

```bash
# Firecrawl APIï¼ˆ4ä¸ªå¯†é’¥æ”¯æŒè½®æ¢ï¼‰
FIRECRAWL_API_KEY=fc-xxx
FIRECRAWL_API_KEY_BACKUP_1=fc-xxx
FIRECRAWL_API_KEY_BACKUP_2=fc-xxx
FIRECRAWL_API_KEY_BACKUP_3=fc-xxx

# æˆæœ¬æ§åˆ¶
FIRECRAWL_DAILY_BUDGET=10.0
FIRECRAWL_TIMEOUT=60

# NewsAPI
NEWSAPI_KEY=your_api_key_here
NEWSAPI_PLAN=developer
NEWSAPI_RATE_LIMIT=100
```

---

## å¼€å‘å·¥ä½œæµ

### 1. åˆ›å»ºåŠŸèƒ½è§„èŒƒ

```bash
# ä½¿ç”¨ OpenSpec åˆ›å»ºå˜æ›´ææ¡ˆ
/openspec:proposal æ·»åŠ å¤å¨å¤·ç§Ÿæˆ¿ä¿¡æ¯çˆ¬è™«
```

### 2. å®¡æŸ¥å’ŒéªŒè¯

```bash
openspec list                          # æŸ¥çœ‹æ´»åŠ¨å˜æ›´
openspec validate add-rental-scraper   # éªŒè¯è§„èŒƒæ ¼å¼
openspec show add-rental-scraper       # å®¡æŸ¥è¯¦ç»†å†…å®¹
```

### 3. å®æ–½å˜æ›´

```bash
# è®© AI å®æ–½ä»»åŠ¡
/openspec:apply add-rental-scraper
```

### 4. å½’æ¡£å®Œæˆçš„å˜æ›´

```bash
openspec archive add-rental-scraper --yes
```

---

## å‚è€ƒèµ„æº

### æ ¸å¿ƒæ–‡æ¡£

- **SDK é…ç½®**: `SDK_CONFIGURATION_COMPLETE.md`
- **Firecrawl è§„åˆ™**: `.cursor/rules/00-hawaiihub-core.mdc`
- **å¿«é€Ÿå¯åŠ¨**: `QUICK_REFERENCE.md`
- **æ€§èƒ½ä¼˜åŒ–**: `CURSOR_æ€§èƒ½ä¼˜åŒ–å®ŒæˆæŠ¥å‘Š_2025-10-28.md`

### å­¦ä¹ èµ„æº

- **Firecrawl å­¦ä¹ æ‰‹å†Œ**: `Firecrawlå­¦ä¹ æ‰‹å†Œ/` ç›®å½•
- **æ¨¡æ¿åº“**: `FIRECRAWL_TEMPLATES_CATALOG.md`ï¼ˆ55ä¸ªæ¨¡æ¿ï¼‰
- **æ•°æ®æºç›®å½•**: `HAWAIIHUB_DATA_SOURCES_CATALOG.md`

### åœ¨çº¿èµ„æº

- Firecrawl æ–‡æ¡£: https://docs.firecrawl.dev/
- NewsAPI æ–‡æ¡£: https://newsapi.org/docs
- OpenSpec å®˜ç½‘: https://openspec.dev/

---

## è´¨é‡ä¿è¯

### ä»£ç å®¡æŸ¥æ£€æŸ¥æ¸…å•

- [ ] æ‰€æœ‰å‡½æ•°æœ‰ç±»å‹æ³¨è§£å’Œä¸­æ–‡ docstring
- [ ] ä½¿ç”¨ç¯å¢ƒå˜é‡è¯»å– API å¯†é’¥
- [ ] å®ç°å®Œæ•´é”™è¯¯å¤„ç†ï¼ˆtry-except + é‡è¯•ï¼‰
- [ ] è®°å½•æ—¥å¿—ï¼ˆlogging.info/warning/errorï¼‰
- [ ] æ•°æ®ä¿å­˜ 3 ç§æ ¼å¼ï¼ˆMD + JSON + CSVï¼‰
- [ ] ä½¿ç”¨ Pydantic éªŒè¯æ•°æ®
- [ ] Git æäº¤ä¿¡æ¯ç¬¦åˆ Conventional Commits
- [ ] é€šè¿‡ Ruff æ ¼å¼åŒ–å’Œ mypy ç±»å‹æ£€æŸ¥

### æµ‹è¯•è¦æ±‚

- ä½¿ç”¨ pytestï¼ˆä¸ä½¿ç”¨ unittestï¼‰
- æ‰€æœ‰æµ‹è¯•å¿…é¡»æœ‰ç±»å‹æ³¨è§£å’Œ docstrings
- æµ‹è¯•ä½ç½®ï¼š`./tests/` ç›®å½•
- Mock å¤–éƒ¨ API è°ƒç”¨

---

## æ›´æ–°è®°å½•

- **2025-10-28**: åˆå§‹åŒ– OpenSpec é¡¹ç›®è§„èŒƒ
- **2025-10-27**: Firecrawl SDK v2 é…ç½®å®Œæˆ
- **2025-10-26**: NewsAPI å…¨å±€é›†æˆ
- **2025-10-24**: Cursor AI å›¢é˜Ÿè§„èŒƒä¼˜åŒ–

---

**ç»´æŠ¤è€…**: HawaiiHub AI Team
**ç‰ˆæœ¬**: v1.0.0
**é€‚ç”¨é¡¹ç›®**: FireShot + HawaiiHub
