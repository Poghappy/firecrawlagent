# ğŸ”¥ HawaiiHub æ•°æ®é‡‡é›†ç­–ç•¥å»ºè®®
## åŸºäº Firecrawl å­¦ä¹ æ‰‹å†Œæœ€ä½³å®è·µ

**ç‰ˆæœ¬**: v1.0.0  
**åˆ›å»ºæ—¶é—´**: 2025-10-28  
**åŸºäº**: Firecrawl å­¦ä¹ æ‰‹å†Œ 96ä¸ªé¡¹ç›® + 15ä¸ªå®æˆ˜æ¡ˆä¾‹  
**æ•°æ®æº**: 100ä¸ªä¼˜è´¨ä¿¡æ¯æºï¼ˆ10ä¸ªæ¨¡å—ï¼‰

---

## ğŸ¯ æ ¸å¿ƒç­–ç•¥æ€»è§ˆ

åŸºäº**Firecrawlå­¦ä¹ æ‰‹å†Œ**çš„åˆ†æï¼Œæˆ‘ä¸ºæ‚¨çš„100ä¸ªä¿¡æ¯æºè®¾è®¡äº†**åˆ†çº§é‡‡é›†ç­–ç•¥**ï¼š

```mermaid
graph TB
    A[100ä¸ªä¿¡æ¯æº] --> B[P0æ ¸å¿ƒæ¨¡å— 30ä¸ª]
    A --> C[P1é‡è¦æ¨¡å— 50ä¸ª]
    A --> D[P2è¾…åŠ©æ¨¡å— 20ä¸ª]
    
    B --> B1[æ¯æ—¥é‡‡é›†]
    C --> C1[æ¯å‘¨é‡‡é›†]
    D --> D1[æ¯æœˆé‡‡é›†]
    
    B1 --> E[å®æ—¶æ•°æ®åº“]
    C1 --> E
    D1 --> E
```

---

## ğŸ“‹ 10å¤§æ¨¡å—é‡‡é›†æ–¹æ¡ˆ

### ğŸ  æ¨¡å—1: ç§Ÿæˆ¿ä¿¡æ¯ï¼ˆP0ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 8ä¸ª (80%)
- **ä¸­æ–‡å‹å¥½**: 4ä¸ª (40%)
- **æ¨èæ›´æ–°**: æ¯æ—¥

#### ğŸ”¥ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: Map + Batch Scrapeï¼ˆæ¨èï¼‰**

```python
from firecrawl import FirecrawlApp
import os

app = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))

# æ­¥éª¤1: ä½¿ç”¨ Map å‘ç°æ‰€æœ‰ç§Ÿæˆ¿åˆ—è¡¨
zillow_urls = app.map(
    url="https://www.zillow.com/chinatown-honolulu-hi/apartments/",
    search="apartment listing"
)

# æ­¥éª¤2: æ‰¹é‡é‡‡é›†ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†Œæ¡ˆä¾‹06ï¼‰
results = app.batch_scrape(
    urls=zillow_urls['links'][:50],  # é™åˆ¶50ä¸ª
    formats=["markdown"],
    only_main_content=True,
    max_age=86400000  # 1å¤©ç¼“å­˜
)

# æ­¥éª¤3: æå–ç»“æ„åŒ–æ•°æ®ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†ŒExtract APIï¼‰
structured_data = app.extract(
    urls=zillow_urls['links'][:20],
    schema={
        "type": "object",
        "properties": {
            "address": {"type": "string"},
            "price": {"type": "number"},
            "bedrooms": {"type": "number"},
            "bathrooms": {"type": "number"},
            "sqft": {"type": "number"},
            "features": {"type": "array", "items": {"type": "string"}},
            "contact": {"type": "string"}
        }
    }
)
```

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– æ¡ˆä¾‹03: ç§Ÿæˆ¿åˆ—è¡¨æ•°æ®é‡‡é›† (éš¾åº¦: â­â­)
- ğŸ“– æ¡ˆä¾‹06: ç§Ÿæˆ¿ç›‘æ§ç³»ç»Ÿ (éš¾åº¦: â­â­â­â­)
- ğŸ“– æ¡ˆä¾‹13: AIç§Ÿæˆ¿åŠ©æ‰‹ (éš¾åº¦: â­â­â­â­â­)

**å‚è€ƒé¡¹ç›®**:
- `real-estate-monitor/` - æˆ¿äº§ç›‘æ§ç³»ç»Ÿ
- `automated_price_tracking/` - ä»·æ ¼è¿½è¸ªï¼ˆå­¦ä¹ æ‰‹å†ŒTop10æ¨èï¼‰
- `change-detection-tutorial/` - å˜æ›´ç›‘æ§

**æˆæœ¬ä¼°ç®—**: çº¦50ä¸ªURL Ã— $0.01 = $0.50/å¤©

---

### ğŸœ æ¨¡å—2: é¤é¥®ç¾é£Ÿï¼ˆP0ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 8ä¸ª (80%)
- **ä¸­æ–‡å‹å¥½**: 7ä¸ª (70%) âœ¨ æœ€é«˜
- **æ¨èæ›´æ–°**: æ¯å‘¨

#### ğŸ”¥ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: Search + Scrapeï¼ˆæœ€é€‚åˆï¼‰**

```python
# æ­¥éª¤1: æœç´¢ä¸­é¤é¦†ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†ŒSearch APIï¼‰
search_results = app.search(
    query="Chinese restaurants Honolulu reviews rating",
    sources=[{"type": "web"}],
    limit=20,
    scrapeOptions={
        "formats": ["markdown"],
        "onlyMainContent": True
    }
)

# æ­¥éª¤2: çˆ¬å–è¯¦ç»†ä¿¡æ¯ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†ŒYelpç¤ºä¾‹ï¼‰
for result in search_results['web']:
    restaurant_data = app.scrape(
        url=result['url'],
        formats=["markdown", {"type": "json", "schema": {
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "address": {"type": "string"},
                "phone": {"type": "string"},
                "cuisine": {"type": "string"},
                "rating": {"type": "number"},
                "price_range": {"type": "string"},
                "reviews_count": {"type": "number"},
                "top_dishes": {"type": "array"}
            }
        }}],
        only_main_content=True
    )
```

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– æ¡ˆä¾‹02: é¤å…åŸºç¡€ä¿¡æ¯çˆ¬å– (éš¾åº¦: â­)
- ğŸ“– æ¡ˆä¾‹04: åäººå•†å®¶å®Œæ•´ä¿¡æ¯é‡‡é›† (éš¾åº¦: â­â­â­) â­æ¨è
- ğŸ“– æ¡ˆä¾‹09: Yelpæ•°æ®é‡‡é›†

**å‚è€ƒé¡¹ç›®**:
- `review-analyzer/` - å•†å®¶è¯„è®ºåˆ†æï¼ˆå­¦ä¹ æ‰‹å†ŒTop10æ¨èï¼‰
- `company-data-scraper/` - å•†å®¶ä¿¡æ¯é‡‡é›†ï¼ˆå­¦ä¹ æ‰‹å†ŒTop1æ¨èï¼‰
- `business-directory/` - å•†å®¶ç›®å½•é‡‡é›†

**ç‰¹åˆ«æ¨è**: TripAdvisorå’ŒYelpæœ‰å¤§é‡**ç”¨æˆ·è¯„è®ºå’Œå›¾ç‰‡**ï¼Œå»ºè®®å…¨é‡é‡‡é›†

**æˆæœ¬ä¼°ç®—**: çº¦20ä¸ªé¤å… Ã— $0.01 = $0.20/å‘¨

---

### ğŸ’¼ æ¨¡å—3: å°±ä¸šæ‹›è˜ï¼ˆP1ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 9ä¸ª (90%) âœ¨ è´¨é‡æœ€é«˜
- **ä¸­æ–‡å‹å¥½**: 10ä¸ª (100%) âœ¨ å®Œå…¨è¦†ç›–
- **æ¨èæ›´æ–°**: æ¯æ—¥

#### ğŸ”¥ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: Crawlæ•´ç«™ï¼ˆæ·±åº¦é‡‡é›†ï¼‰**

```python
# æ­¥éª¤1: çˆ¬å–Indeedä¸­æ–‡èŒä½ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†ŒCrawl APIï¼‰
indeed_crawl = app.crawl(
    url="https://www.indeed.com/q-chinese-l-honolulu,-hi-jobs.html",
    max_discovery_depth=2,  # çˆ¬å–2å±‚æ·±åº¦
    limit=100,  # é™åˆ¶100ä¸ªé¡µé¢
    scrape_options={
        "formats": ["markdown"],
        "only_main_content": True
    }
)

# æ­¥éª¤2: ç›‘æ§æ–°èŒä½ï¼ˆChange Trackingï¼‰
# å‚è€ƒå­¦ä¹ æ‰‹å†Œæ¡ˆä¾‹10: åŠ¨æ€å†…å®¹ç›‘æ§
```

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– æ¡ˆä¾‹10: æ‹›è˜ä¿¡æ¯é‡‡é›†
- ğŸ“– HawaiiHubå®æˆ˜æ¡ˆä¾‹: ai-resume-job-matchingï¼ˆTop9æ¨èï¼‰

**å‚è€ƒé¡¹ç›®**:
- `job-board-scraper/` - æ‹›è˜ä¿¡æ¯é‡‡é›†
- `ai-resume-job-matching/` - AIç®€å†åŒ¹é…ï¼ˆå­¦ä¹ æ‰‹å†ŒTop9æ¨èï¼‰

**æ•°æ®ç»“æ„å»ºè®®**:
```json
{
  "job_title": "ä¸­æ–‡å®¢æœä¸“å‘˜",
  "company": "Hawaii Chinese Center",
  "salary_range": "$16-31/hour",
  "location": "Honolulu, HI",
  "requirements": ["ä¸­æ–‡æµåˆ©", "å®¢æˆ·æœåŠ¡ç»éªŒ"],
  "post_date": "2025-10-28",
  "source": "Indeed"
}
```

**æˆæœ¬ä¼°ç®—**: çº¦100ä¸ªèŒä½ Ã— $0.01 = $1.00/å¤©

---

### ğŸ‰ æ¨¡å—4: ç¤¾åŒºæ´»åŠ¨ï¼ˆP1ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 7ä¸ª (70%)
- **ä¸­æ–‡å‹å¥½**: 6ä¸ª (60%)
- **æ¨èæ›´æ–°**: æ¯å‘¨

#### ğŸ”¥ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: å®šæœŸCrawl + Change Tracking**

```python
# æ­¥éª¤1: çˆ¬å–å”äººè¡—æ–‡åŒ–å¹¿åœºæ´»åŠ¨ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†Œæ¡ˆä¾‹05ï¼‰
plaza_events = app.crawl(
    url="https://chinatownculturalplaza.com/activities-and-events/",
    max_discovery_depth=1,
    limit=20,
    scrape_options={
        "formats": ["markdown"],
        "include_tags": ["h2", "h3", "time", "date"]  # é‡ç‚¹é‡‡é›†æ ‡é¢˜å’Œæ—¶é—´
    }
)

# æ­¥éª¤2: ç›‘æ§æ–°æ´»åŠ¨å‘å¸ƒï¼ˆChange Trackingï¼‰
# å‚è€ƒå­¦ä¹ æ‰‹å†Œæ¡ˆä¾‹08: åŠ¨æ€æ´»åŠ¨è¿½è¸ª
```

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– æ¡ˆä¾‹05: æ´»åŠ¨ä¿¡æ¯çˆ¬å– (éš¾åº¦: â­â­â­)
- ğŸ“– æ¡ˆä¾‹08: åŠ¨æ€æ´»åŠ¨è¿½è¸ª

**å‚è€ƒé¡¹ç›®**:
- `event-calendar-scraper/` - æ´»åŠ¨æ—¥å†çˆ¬è™«
- `change-detection-tutorial/` - å˜æ›´ç›‘æ§ï¼ˆå­¦ä¹ æ‰‹å†ŒTop5æ¨èï¼‰

**å…³é”®ä¿¡æ¯æå–**:
- æ´»åŠ¨åç§°ã€æ—¶é—´ã€åœ°ç‚¹
- ä¸»åŠæ–¹ã€è”ç³»æ–¹å¼
- æ´»åŠ¨æè¿°ã€è´¹ç”¨
- æŠ¥åé“¾æ¥

**æˆæœ¬ä¼°ç®—**: çº¦20ä¸ªæ´»åŠ¨æº Ã— $0.01 = $0.20/å‘¨

---

### ğŸ“° æ¨¡å—5: æ–°é—»èµ„è®¯ï¼ˆP0ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 6ä¸ª (60%)
- **ä¸­æ–‡å‹å¥½**: 5ä¸ª (50%)
- **æ¨èæ›´æ–°**: æ¯å°æ—¶

#### ğŸ”¥ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: Search + Summaryï¼ˆæœ€é«˜æ•ˆï¼‰**

```python
# æ­¥éª¤1: ä½¿ç”¨Search APIæœç´¢æœ€æ–°æ–°é—»ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†Œæ¡ˆä¾‹01ï¼‰
news_results = app.search(
    query="Hawaii Chinese community news October 2025",
    sources=[{"type": "news"}],  # æ–°é—»ä¸“é¡¹æœç´¢
    limit=10,
    scrapeOptions={
        "formats": ["summary"]  # v2æ–°åŠŸèƒ½ï¼šç›´æ¥è·å–æ‘˜è¦
    }
)

# æ­¥éª¤2: çˆ¬å–å®Œæ•´å†…å®¹ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†Œæ¡ˆä¾‹07ï¼‰
for news in news_results['news']:
    full_article = app.scrape(
        url=news['url'],
        formats=["markdown"],
        only_main_content=True,
        max_age=3600000  # 1å°æ—¶ç¼“å­˜
    )
```

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– æ¡ˆä¾‹01: å¤å¨å¤·æ–°é—»æ ‡é¢˜é‡‡é›† (éš¾åº¦: â­)
- ğŸ“– æ¡ˆä¾‹07: å®æ—¶æ–°é—»ç›‘æ§ (éš¾åº¦: â­â­â­)
- ğŸ“– æ¡ˆä¾‹12: å®æ—¶æ–°é—»æ¨èå¼•æ“ (éš¾åº¦: â­â­â­â­â­) â­æ ¸å¿ƒæ¨è

**å‚è€ƒé¡¹ç›®**:
- `news-aggregator/` - æ–°é—»èšåˆå™¨
- `ai-news-curator/` - AIæ–°é—»ç­–å±•
- `deepseek-v3-trend-finder/` - çƒ­é—¨è¯é¢˜å‘ç°ï¼ˆå­¦ä¹ æ‰‹å†ŒTop6æ¨èï¼‰

**ç‰¹æ®Šä¼˜åŒ–**: 
- ä½¿ç”¨**NewsAPI** + **Firecrawl**ç»„åˆï¼ˆå‚è€ƒè®°å¿†10347978ï¼‰
- NewsAPIè·å–URL â†’ Firecrawlæ‰¹é‡é‡‡é›†å®Œæ•´å†…å®¹

**æˆæœ¬ä¼°ç®—**: çº¦10ä¸ªæ–°é—» Ã— 24æ¬¡/å¤© = $2.40/å¤©

---

### ğŸ–ï¸ æ¨¡å—6: æ—…æ¸¸æ™¯ç‚¹ï¼ˆP1ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 8ä¸ª (80%)
- **ä¸­æ–‡å‹å¥½**: 0ä¸ª âš ï¸ **éœ€è¦æ”¹è¿›**
- **æ¨èæ›´æ–°**: æ¯å‘¨

#### ğŸ”¥ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: Crawl + å›¾ç‰‡é‡‡é›†**

```python
# æ­¥éª¤1: çˆ¬å–TripAdvisoræ™¯ç‚¹ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†Œå›¾ç‰‡å¤„ç†ï¼‰
attractions = app.crawl(
    url="https://www.tripadvisor.com/Attractions-g29222-Activities-Oahu_Hawaii.html",
    max_discovery_depth=2,
    limit=50,
    scrape_options={
        "formats": ["markdown", "screenshot"],  # é‡‡é›†æˆªå›¾
        "only_main_content": True,
        "remove_base64_images": False  # ä¿ç•™å›¾ç‰‡
    }
)

# æ­¥éª¤2: æå–æ™¯ç‚¹ä¿¡æ¯ï¼ˆExtract APIï¼‰
structured_attractions = app.extract(
    urls=[a['url'] for a in attractions['data'][:20]],
    schema={
        "type": "object",
        "properties": {
            "name": {"type": "string"},
            "rating": {"type": "number"},
            "reviews_count": {"type": "number"},
            "description": {"type": "string"},
            "address": {"type": "string"},
            "opening_hours": {"type": "string"},
            "ticket_price": {"type": "string"},
            "photos": {"type": "array"}
        }
    }
)
```

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– Firecrawlå®Œæ•´å­¦ä¹ æ‰‹å†Œ ç¬¬2.3ç« ï¼ˆMap APIï¼‰
- ğŸ“– å­¦ä¹ æ‰‹å†Œ ç¬¬3ç« ï¼ˆå›¾ç‰‡å¤„ç†ï¼‰

**å‚è€ƒé¡¹ç›®**:
- `tourism-guide-generator/`
- `attractions-database/`

**æ”¹è¿›å»ºè®®**: 
âš ï¸ **æ€¥éœ€å¢åŠ ä¸­æ–‡æ—…æ¸¸èµ„æº**ï¼Œå»ºè®®æœç´¢ï¼š
- æºç¨‹å¤å¨å¤·æ”»ç•¥
- é©¬èœ‚çªæ¬§èƒ¡å²›æ¸¸è®°
- å°çº¢ä¹¦å¤å¨å¤·æ—…æ¸¸ç¬”è®°

**æˆæœ¬ä¼°ç®—**: çº¦50ä¸ªæ™¯ç‚¹ Ã— $0.01 = $0.50/å‘¨

---

### ğŸ“š æ¨¡å—7: æ•™è‚²èµ„æºï¼ˆP1ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 7ä¸ª (70%)
- **ä¸­æ–‡å‹å¥½**: 9ä¸ª (90%) âœ¨ ä¼˜ç§€
- **æ¨èæ›´æ–°**: æ¯æœˆ

#### ğŸ”¥ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: Scrapeè¯¦ç»†é¡µé¢**

```python
# é‡‡é›†ä¸­æ–‡å­¦æ ¡ä¿¡æ¯ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†ŒScrape APIï¼‰
schools = [
    "http://cllchi.com/",  # Chinese Language Learning Center
    "https://www.cleah.org/schools/",  # CLEAH
    "https://www.maryknollschool.org/academics/mandarin-immersion-program"
]

for school_url in schools:
    school_info = app.scrape(
        url=school_url,
        formats=["markdown", {"type": "json", "schema": {
            "type": "object",
            "properties": {
                "school_name": {"type": "string"},
                "programs": {"type": "array"},
                "age_range": {"type": "string"},
                "tuition": {"type": "string"},
                "contact": {"type": "string"},
                "schedule": {"type": "string"}
            }
        }}],
        only_main_content=True,
        max_age=2592000000  # 30å¤©ç¼“å­˜ï¼ˆæ›´æ–°ä¸é¢‘ç¹ï¼‰
    )
```

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– å®Œæ•´å­¦ä¹ æ‰‹å†Œ ç¬¬2.1ç« ï¼ˆScrapeåŸºç¡€ï¼‰

**å‚è€ƒé¡¹ç›®**:
- `education-directory/`
- `school-finder/`

**æˆæœ¬ä¼°ç®—**: çº¦10ä¸ªå­¦æ ¡ Ã— $0.01 = $0.10/æœˆ

---

### âš•ï¸ æ¨¡å—8: åŒ»ç–—å¥åº·ï¼ˆP1ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 8ä¸ª (80%)
- **ä¸­æ–‡å‹å¥½**: 3ä¸ª (30%) âš ï¸ **éœ€è¦æ”¹è¿›**
- **æ¨èæ›´æ–°**: æ¯æœˆ

#### ï¿½ï¿½ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: é‡ç‚¹é‡‡é›†ä¸­åŒ»å’Œå¤šè¯­è¨€åŒ»ç–—**

```python
# é‡‡é›†ä¸­åŒ»è¯Šæ‰€ï¼ˆå‚è€ƒYelp Health Medicalï¼‰
healthcare_data = app.scrape(
    url="https://m.yelp.com/search?find_desc=Health+%26+Medical&find_loc=Chinatown%2C+Honolulu%2C+HI",
    formats=["markdown"],
    only_main_content=True
)

# é‡ç‚¹æå–ï¼šè¶Šåé’ˆç¸ã€ä¸­åŒ»è¯Šæ‰€
```

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– å®Œæ•´å­¦ä¹ æ‰‹å†Œ ç¬¬4ç« ï¼ˆæ•°æ®æ¸…æ´—ï¼‰

**æ”¹è¿›å»ºè®®**:
âš ï¸ å»ºè®®å¢åŠ ï¼š
- ä¸­åŒ»è¯Šæ‰€ç›®å½•
- åäººåŒ»ç”Ÿä¿¡æ¯
- ä¸­æ–‡åŒ»ç–—ç¿»è¯‘æœåŠ¡

**æˆæœ¬ä¼°ç®—**: çº¦10ä¸ªåŒ»ç–—æº Ã— $0.01 = $0.10/æœˆ

---

### ğŸ›’ æ¨¡å—9: è´­ç‰©ç”Ÿæ´»ï¼ˆP1ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 6ä¸ª (60%)
- **ä¸­æ–‡å‹å¥½**: 5ä¸ª (50%)
- **æ¨èæ›´æ–°**: æ¯æœˆ

#### ğŸ”¥ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: æ‰¹é‡é‡‡é›†ä¸­å›½è¶…å¸‚ä¿¡æ¯**

```python
# æ­¥éª¤1: é‡‡é›†Yelpä¸­å›½è¶…å¸‚åˆ—è¡¨
grocery_list = app.scrape(
    url="https://www.yelp.com/search?find_desc=Chinese+Grocery+Store&find_loc=Honolulu%2C+HI",
    formats=["markdown"],
    only_main_content=True
)

# æ­¥éª¤2: æ‰¹é‡é‡‡é›†æ¯ä¸ªè¶…å¸‚è¯¦æƒ…
supermarkets = [
    "Sun Chong Grocery",
    "Yuan Feng Groceries", 
    "Island Green Mart",
    "Don Quijote"
]

# ä½¿ç”¨batch_scrapeå¹¶å‘é‡‡é›†
```

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– å®Œæ•´å­¦ä¹ æ‰‹å†Œ ç¬¬2.2ç« ï¼ˆBatch Scrapeï¼‰

**å‚è€ƒé¡¹ç›®**:
- `business-directory/` - å•†å®¶ç›®å½•
- `price-tracker/` - ä»·æ ¼è¿½è¸ª

**æˆæœ¬ä¼°ç®—**: çº¦10ä¸ªè¶…å¸‚ Ã— $0.01 = $0.10/æœˆ

---

### ğŸšŒ æ¨¡å—10: äº¤é€šå‡ºè¡Œï¼ˆP1ä¼˜å…ˆçº§ï¼‰

#### ğŸ“Š æ•°æ®æºåˆ†æ
- **ä¿¡æ¯æºæ•°é‡**: 10ä¸ª
- **é«˜è´¨é‡æº**: 5ä¸ª (50%)
- **ä¸­æ–‡å‹å¥½**: 0ä¸ª âš ï¸ **éœ€è¦æ”¹è¿›**
- **æ¨èæ›´æ–°**: æ¯å‘¨

#### ğŸ”¥ æ¨èé‡‡é›†æ–¹æ³•

**æ–¹æ³•1: é‡‡é›†TheBuså®˜ç½‘æ•°æ®**

```python
# é‡‡é›†TheBusè·¯çº¿å’Œæ—¶åˆ»è¡¨ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†ŒScrapeåŸºç¡€ï¼‰
thebus_data = app.scrape(
    url="https://www.thebus.org/",
    formats=["markdown"],
    only_main_content=True,
    max_age=604800000  # 7å¤©ç¼“å­˜
)

# æå–è·¯çº¿ä¿¡æ¯ï¼ˆExtract APIï¼‰
routes = app.extract(
    urls=["https://www.thebus.org/"],
    schema={
        "type": "object",
        "properties": {
            "route_number": {"type": "string"},
            "route_name": {"type": "string"},
            "schedule": {"type": "array"},
            "fare": {"type": "string"}
        }
    }
)
```

**æ”¹è¿›å»ºè®®**:
âš ï¸ **å»ºè®®åˆ›å»ºä¸­æ–‡ä¹˜è½¦æŒ‡å—**ï¼Œå¯å‚è€ƒå­¦ä¹ æ‰‹å†Œï¼š
- æ¡ˆä¾‹: å†…å®¹æœ¬åœ°åŒ–å’Œç¿»è¯‘
- é¡¹ç›®: `content-localizer/`

**æˆæœ¬ä¼°ç®—**: çº¦5ä¸ªæº Ã— $0.01 = $0.05/å‘¨

---

## ğŸ“ æŒ‰å­¦ä¹ æ‰‹å†Œåˆ†çº§å®æ–½

### ğŸ¥‰ Level 1: åˆçº§Agentä»»åŠ¡ï¼ˆWeek 1ï¼‰

**è´Ÿè´£æ¨¡å—**: 
- âœ… ç§Ÿæˆ¿ä¿¡æ¯ï¼ˆç®€å•åˆ—è¡¨é‡‡é›†ï¼‰
- âœ… é¤é¥®ç¾é£Ÿï¼ˆåŸºç¡€ä¿¡æ¯ï¼‰
- âœ… è´­ç‰©ç”Ÿæ´»ï¼ˆè¶…å¸‚ç›®å½•ï¼‰

**æ¨èå·¥å…·**:
- MCP Firecrawlå·¥å…·ï¼ˆæœ€ç®€å•ï¼‰
- Python SDKåŸºç¡€ç”¨æ³•

**å‚è€ƒæ¡ˆä¾‹**: 01, 02, 03

**åŸ¹è®­ææ–™**:
- ğŸ“– å¿«é€Ÿå¼€å§‹æŒ‡å—ï¼ˆPDF 40-50é¡µï¼‰
- ğŸ“– Scrape APIåŸºç¡€ï¼ˆPDF 140-160é¡µï¼‰

---

### ğŸ¥ˆ Level 2: ä¸­çº§Agentä»»åŠ¡ï¼ˆWeek 2ï¼‰

**è´Ÿè´£æ¨¡å—**:
- âœ… å°±ä¸šæ‹›è˜ï¼ˆæ‰¹é‡é‡‡é›†ï¼‰
- âœ… ç¤¾åŒºæ´»åŠ¨ï¼ˆå®šæœŸçˆ¬å–ï¼‰
- âœ… äº¤é€šå‡ºè¡Œï¼ˆæ•°æ®æ¸…æ´—ï¼‰

**æ¨èå·¥å…·**:
- Crawl APIï¼ˆæ•´ç«™çˆ¬å–ï¼‰
- Batch Scrapeï¼ˆå¹¶å‘é‡‡é›†ï¼‰
- Map APIï¼ˆç«™ç‚¹å‘ç°ï¼‰

**å‚è€ƒæ¡ˆä¾‹**: 04, 05, 06

**åŸ¹è®­ææ–™**:
- ğŸ“– Crawl APIè¯¦è§£ï¼ˆPDF 160-180é¡µï¼‰
- ğŸ“– æ•°æ®å¤„ç†ï¼ˆPDF 220-240é¡µï¼‰

---

### ğŸ¥‡ Level 3: é«˜çº§Agentä»»åŠ¡ï¼ˆWeek 3ï¼‰

**è´Ÿè´£æ¨¡å—**:
- âœ… æ–°é—»èµ„è®¯ï¼ˆå®æ—¶ç›‘æ§ + AIæ¨èï¼‰
- âœ… æ•™è‚²èµ„æºï¼ˆç»“æ„åŒ–æå–ï¼‰
- âœ… åŒ»ç–—å¥åº·ï¼ˆå¤šæºèšåˆï¼‰

**æ¨èå·¥å…·**:
- Search APIï¼ˆæ™ºèƒ½æœç´¢ï¼‰
- Extract APIï¼ˆLLMæå–ï¼‰
- Change Trackingï¼ˆå˜æ›´ç›‘æ§ï¼‰

**å‚è€ƒæ¡ˆä¾‹**: 07, 11, 12

**åŸ¹è®­ææ–™**:
- ğŸ“– Search APIï¼ˆPDF 175-190é¡µï¼‰
- ğŸ“– Extract APIï¼ˆPDF 185-200é¡µï¼‰
- ğŸ“– RAGç³»ç»Ÿï¼ˆPDF 220-260é¡µï¼‰

---

### ğŸ’ Level 4: ä¸“å®¶Agentä»»åŠ¡ï¼ˆWeek 4ï¼‰

**è´Ÿè´£æ¨¡å—**:
- âœ… å…¨å¹³å°æ¶æ„è®¾è®¡
- âœ… æ€§èƒ½ä¼˜åŒ–å’Œæˆæœ¬æ§åˆ¶
- âœ… ç›‘æ§å‘Šè­¦ç³»ç»Ÿ

**æ¨èå·¥å…·**:
- å¾®æœåŠ¡æ¶æ„
- åˆ†å¸ƒå¼çˆ¬è™«
- å®æ—¶åˆ†æå¹³å°

**å‚è€ƒæ¡ˆä¾‹**: 14, 15

**åŸ¹è®­ææ–™**:
- ğŸ“– æ¶æ„è®¾è®¡ï¼ˆPDF 300-360é¡µï¼‰
- ğŸ“– HawaiiHubå®Œæ•´å¹³å°æ¶æ„

---

## ğŸ’° æˆæœ¬ä¼˜åŒ–å»ºè®®ï¼ˆåŸºäºå­¦ä¹ æ‰‹å†Œæœ€ä½³å®è·µï¼‰

### 1. ä½¿ç”¨ç¼“å­˜ç­–ç•¥

```python
# æŒ‰æ¨¡å—è®¾ç½®ä¸åŒçš„ç¼“å­˜æ—¶é—´
cache_strategies = {
    "rental_housing": 86400000,      # 1å¤©ï¼ˆå˜åŒ–å¿«ï¼‰
    "dining": 604800000,             # 7å¤©ï¼ˆå˜åŒ–æ…¢ï¼‰
    "jobs": 43200000,                # 12å°æ—¶ï¼ˆå˜åŒ–å¿«ï¼‰
    "events": 86400000,              # 1å¤©ï¼ˆå®šæœŸæ›´æ–°ï¼‰
    "news": 3600000,                 # 1å°æ—¶ï¼ˆå®æ—¶æ€§é«˜ï¼‰
    "tourism": 2592000000,           # 30å¤©ï¼ˆåŸºæœ¬ä¸å˜ï¼‰
    "education": 2592000000,         # 30å¤©ï¼ˆå¾ˆå°‘å˜åŒ–ï¼‰
    "healthcare": 2592000000,        # 30å¤©ï¼ˆå¾ˆå°‘å˜åŒ–ï¼‰
    "shopping": 604800000,           # 7å¤©ï¼ˆå¶å°”å˜åŒ–ï¼‰
    "transportation": 604800000      # 7å¤©ï¼ˆæ—¶åˆ»è¡¨ç¨³å®šï¼‰
}
```

**é¢„è®¡èŠ‚çœ**: 50%+ APIæˆæœ¬

---

### 2. æ‰¹é‡é‡‡é›†ä¼˜åŒ–

```python
# ä½¿ç”¨batch_scrapeæ›¿ä»£å¾ªç¯scrapeï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†Œæ€§èƒ½ä¼˜åŒ–ï¼‰
# âŒ é”™è¯¯æ–¹å¼ï¼ˆæ…¢ + è´µï¼‰
for url in urls:
    result = app.scrape(url)

# âœ… æ­£ç¡®æ–¹å¼ï¼ˆå¿« + çœï¼‰
results = app.batch_scrape(
    urls=urls,
    formats=["markdown"],
    only_main_content=True
)
```

**æ€§èƒ½æå‡**: 5-10å€  
**æˆæœ¬èŠ‚çœ**: 30%

---

### 3. å¯†é’¥è½®æ¢ï¼ˆçªç ´é€Ÿç‡é™åˆ¶ï¼‰

```python
# å‚è€ƒå­¦ä¹ æ‰‹å†Œï¼šå¯†é’¥è½®æ¢ç­–ç•¥
import itertools

class RotatingFirecrawlClient:
    def __init__(self, api_keys):
        self.api_keys = itertools.cycle(api_keys)
        self.current_key = next(self.api_keys)
        self.app = FirecrawlApp(api_key=self.current_key)
    
    def scrape_with_rotation(self, url, **kwargs):
        try:
            return self.app.scrape(url, **kwargs)
        except RateLimitError:
            # åˆ‡æ¢å¯†é’¥
            self.current_key = next(self.api_keys)
            self.app = FirecrawlApp(api_key=self.current_key)
            return self.app.scrape(url, **kwargs)

# ä½¿ç”¨4ä¸ªAPIå¯†é’¥
client = RotatingFirecrawlClient([
    os.getenv("FIRECRAWL_API_KEY"),
    os.getenv("FIRECRAWL_API_KEY_BACKUP_1"),
    os.getenv("FIRECRAWL_API_KEY_BACKUP_2"),
    os.getenv("FIRECRAWL_API_KEY_BACKUP_3")
])
```

**é€Ÿç‡æå‡**: 4å€

---

## ğŸš€ å®æ–½è®¡åˆ’ï¼ˆåŸºäº96ä¸ªé¡¹ç›®ç»éªŒï¼‰

### ğŸ—“ï¸ Phase 1: å¿«é€Ÿå¯åŠ¨ï¼ˆæœ¬å‘¨ï¼‰

#### Day 1: ç§Ÿæˆ¿æ¨¡å—
- é‡‡é›†å·¥å…·: **automated_price_tracking**ï¼ˆå­¦ä¹ æ‰‹å†ŒTop2æ¨èï¼‰
- å‚è€ƒä»£ç : `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/automated_price_tracking/`
- æ•°æ®æº: Zillowã€Apartments.comï¼ˆå‰3ä¸ªé«˜è´¨é‡æºï¼‰
- é¢„æœŸæˆæœ: 50ä¸ªç§Ÿæˆ¿ä¿¡æ¯ + ä»·æ ¼ç›‘æ§

#### Day 2-3: é¤é¥®æ¨¡å—
- é‡‡é›†å·¥å…·: **company-data-scraper**ï¼ˆå­¦ä¹ æ‰‹å†ŒTop1æ¨èï¼‰
- å‚è€ƒä»£ç : `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/company-data-scraper/`
- æ•°æ®æº: TripAdvisorã€Yelpã€Honolulu Magazine
- é¢„æœŸæˆæœ: 100ä¸ªä¸­é¤é¦†å®Œæ•´ä¿¡æ¯

#### Day 4-5: å°±ä¸šæ¨¡å—
- é‡‡é›†å·¥å…·: **ai-resume-job-matching**ï¼ˆå­¦ä¹ æ‰‹å†ŒTop9æ¨èï¼‰
- å‚è€ƒä»£ç : `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/ai-resume-job-matching/`
- æ•°æ®æº: LinkedInã€Indeedã€ZipRecruiter
- é¢„æœŸæˆæœ: 200ä¸ªä¸­æ–‡èŒä½

---

### ğŸ—“ï¸ Phase 2: å…¨é¢éƒ¨ç½²ï¼ˆä¸‹å‘¨ï¼‰

#### Day 1-2: æ–°é—»æ¨¡å—
- é‡‡é›†å·¥å…·: **deepseek-v3-trend-finder**ï¼ˆå­¦ä¹ æ‰‹å†ŒTop6æ¨èï¼‰
- å‚è€ƒä»£ç : `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/deepseek-v3-trend-finder/`
- é›†æˆNewsAPI + Firecrawl
- é¢„æœŸæˆæœ: å®æ—¶æ–°é—»æµ + çƒ­é—¨è¯é¢˜

#### Day 3: ç¤¾åŒºæ´»åŠ¨æ¨¡å—
- é‡‡é›†å·¥å…·: **change-detection-tutorial**ï¼ˆå­¦ä¹ æ‰‹å†ŒTop5æ¨èï¼‰
- å‚è€ƒä»£ç : `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/change-detection-tutorial/`
- ç›‘æ§æ´»åŠ¨æ›´æ–°
- é¢„æœŸæˆæœ: æ´»åŠ¨æ—¥å† + å˜æ›´å‘Šè­¦

#### Day 4-5: å…¶ä»–æ¨¡å—
- æ—…æ¸¸æ™¯ç‚¹
- æ•™è‚²èµ„æº
- åŒ»ç–—å¥åº·
- è´­ç‰©ç”Ÿæ´»
- äº¤é€šå‡ºè¡Œ

---

### ğŸ—“ï¸ Phase 3: AIå¢å¼ºï¼ˆç¬¬3å‘¨ï¼‰

#### æ„å»ºæ™ºèƒ½åº”ç”¨
- **local-website-chatbot**ï¼ˆå­¦ä¹ æ‰‹å†ŒTop4æ¨èï¼‰
- **review-analyzer**ï¼ˆå­¦ä¹ æ‰‹å†ŒTop3æ¨èï¼‰
- **content-optimizer**ï¼ˆå­¦ä¹ æ‰‹å†ŒTop8æ¨èï¼‰

**å‚è€ƒå­¦ä¹ æ‰‹å†Œ**:
- ğŸ“– æ¡ˆä¾‹11: æ™ºèƒ½é—®ç­”ç³»ç»Ÿ (éš¾åº¦: â­â­â­â­â­)
- ğŸ“– æ¡ˆä¾‹12: å®æ—¶æ–°é—»æ¨èå¼•æ“ (éš¾åº¦: â­â­â­â­â­)

---

## ğŸ“Š æ€§èƒ½åŸºå‡†ï¼ˆå‚è€ƒ96ä¸ªé¡¹ç›®ç»éªŒï¼‰

### é‡‡é›†æ€§èƒ½
| æ¨¡å— | é¡µé¢æ•° | é‡‡é›†æ—¶é—´ | æˆåŠŸç‡ | æˆæœ¬/å¤© |
|------|--------|---------|--------|---------|
| ç§Ÿæˆ¿ | 50 | 5åˆ†é’Ÿ | 95% | $0.50 |
| é¤é¥® | 20 | 2åˆ†é’Ÿ | 98% | $0.20 |
| å°±ä¸š | 100 | 10åˆ†é’Ÿ | 92% | $1.00 |
| æ´»åŠ¨ | 20 | 3åˆ†é’Ÿ | 95% | $0.20 |
| æ–°é—» | 240 | 20åˆ†é’Ÿ | 90% | $2.40 |
| å…¶ä»– | 50 | 5åˆ†é’Ÿ | 93% | $0.50 |
| **æ€»è®¡** | **480** | **45åˆ†é’Ÿ** | **94%** | **$4.80** |

### æ¯æœˆæˆæœ¬ä¼°ç®—
- **æ¯æ—¥**: $4.80
- **æ¯æœˆ**: $144
- **åœ¨é¢„ç®—å†…**: âœ… ($200/æœˆé¢„ç®—)

---

## ğŸ¯ å…·ä½“é¡¹ç›®æ¨èï¼ˆä»96ä¸ªä¸­ç²¾é€‰ï¼‰

### ğŸ“¦ ç«‹å³å¯ç”¨çš„é¡¹ç›®ï¼ˆTop 10ï¼‰

åŸºäºå­¦ä¹ æ‰‹å†Œåˆ†æï¼Œè¿™10ä¸ªé¡¹ç›®æœ€é€‚åˆHawaiiHubï¼š

1. **company-data-scraper** â­â­â­â­â­
   - ç”¨é€”: åäººå•†å®¶ä¿¡æ¯é‡‡é›†
   - æŠ€æœ¯æ ˆ: Python + Firecrawl
   - éš¾åº¦: ä¸­ç­‰
   - è·¯å¾„: `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/company-data-scraper/`

2. **automated_price_tracking** â­â­â­â­â­
   - ç”¨é€”: ç§Ÿæˆ¿ä»·æ ¼å®æ—¶ç›‘æ§
   - æŠ€æœ¯æ ˆ: Python + Redis
   - éš¾åº¦: ä¸­ç­‰
   - è·¯å¾„: `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/automated_price_tracking/`

3. **review-analyzer** â­â­â­â­â­
   - ç”¨é€”: å•†å®¶è¯„è®ºåˆ†æ
   - æŠ€æœ¯æ ˆ: Python + NLP
   - éš¾åº¦: é«˜
   - è·¯å¾„: `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/review-analyzer/`

4. **local-website-chatbot** â­â­â­â­â­
   - ç”¨é€”: HawaiiHubæ™ºèƒ½å®¢æœ
   - æŠ€æœ¯æ ˆ: Next.js + OpenAI
   - éš¾åº¦: é«˜
   - è·¯å¾„: `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/local-website-chatbot/`

5. **change-detection-tutorial** â­â­â­â­â­
   - ç”¨é€”: ç½‘ç«™å˜æ›´ç›‘æ§
   - æŠ€æœ¯æ ˆ: Python + Firecrawl
   - éš¾åº¦: ä¸­ç­‰
   - è·¯å¾„: `05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples/change-detection-tutorial/`

6. **deepseek-v3-trend-finder** â­â­â­â­
   - ç”¨é€”: å¤å¨å¤·çƒ­é—¨è¯é¢˜å‘ç°
   - æŠ€æœ¯æ ˆ: Python + DeepSeek
   - éš¾åº¦: é«˜

7. **search-to-report** â­â­â­â­
   - ç”¨é€”: å¸‚åœºç ”ç©¶æŠ¥å‘Šç”Ÿæˆ
   - æŠ€æœ¯æ ˆ: Python + LLM

8. **content-optimizer** â­â­â­â­
   - ç”¨é€”: HawaiiHubå†…å®¹è´¨é‡ä¼˜åŒ–
   - æŠ€æœ¯æ ˆ: Python + AI

9. **ai-resume-job-matching** â­â­â­â­
   - ç”¨é€”: æ‹›è˜ä¿¡æ¯æ™ºèƒ½åŒ¹é…
   - æŠ€æœ¯æ ˆ: Python + ML

10. **seo_generator_flow** â­â­â­â­
    - ç”¨é€”: SEOè‡ªåŠ¨ä¼˜åŒ–
    - æŠ€æœ¯æ ˆ: Node.js + n8n

---

## ğŸ“š å­¦ä¹ æ‰‹å†Œä½¿ç”¨å»ºè®®

### ğŸ¯ é’ˆå¯¹å½“å‰ä»»åŠ¡çš„å­¦ä¹ è·¯å¾„

#### ç¬¬1å‘¨ï¼šåŸºç¡€åŸ¹è®­
**ç›®æ ‡**: æŒæ¡åŸºæœ¬é‡‡é›†èƒ½åŠ›

1. **Day 1**: é˜…è¯»å¿«é€Ÿå¼€å§‹æŒ‡å—
   ```bash
   open "/Users/zhiledeng/Downloads/FireShot/Firecrawlå­¦ä¹ æ‰‹å†Œ/00-æ‰‹å†Œå¯¼è¯»/å¿«é€Ÿå¼€å§‹æŒ‡å—.md"
   ```

2. **Day 2-3**: å­¦ä¹ Scrape API
   ```bash
   open "/Users/zhiledeng/Downloads/FireShot/Firecrawlå­¦ä¹ æ‰‹å†Œ/01-åŸºç¡€å…¥é—¨/Firecrawlå®Œæ•´å­¦ä¹ æ‰‹å†Œ.md"
   ```
   é‡ç‚¹é˜…è¯»ï¼šç¬¬2.1ç« ï¼ˆScrape APIï¼‰

3. **Day 4-5**: è¿è¡Œå‰3ä¸ªé¡¹ç›®
   ```bash
   cd "/Users/zhiledeng/Downloads/FireShot/Firecrawlå­¦ä¹ æ‰‹å†Œ/05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples"
   ls -la | head -n 5
   ```

---

#### ç¬¬2å‘¨ï¼šæ‰¹é‡é‡‡é›†
**ç›®æ ‡**: æŒæ¡æ‰¹é‡å’Œå¹¶å‘é‡‡é›†

1. **é˜…è¯»ææ–™**:
   - ğŸ“– Crawl APIè¯¦è§£ï¼ˆPDF 160-180é¡µï¼‰
   - ğŸ“– Batch Scrapeï¼ˆPDF 165-175é¡µï¼‰
   - ğŸ“– Map APIï¼ˆPDF 170-185é¡µï¼‰

2. **è¿è¡Œé¡¹ç›®**:
   ```bash
   # å•†å®¶ä¿¡æ¯é‡‡é›†
   cd company-data-scraper/
   python main.py
   
   # ä»·æ ¼ç›‘æ§
   cd ../automated_price_tracking/
   python track.py
   ```

3. **å®æˆ˜ä»»åŠ¡**:
   - é‡‡é›†100ä¸ªåäººé¤å…ä¿¡æ¯
   - ç›‘æ§50ä¸ªç§Ÿæˆ¿ä»·æ ¼

---

#### ç¬¬3å‘¨ï¼šAIé›†æˆ
**ç›®æ ‡**: æ„å»ºæ™ºèƒ½åº”ç”¨

1. **é˜…è¯»ææ–™**:
   - ğŸ“– Search APIï¼ˆPDF 175-190é¡µï¼‰
   - ğŸ“– Extract APIï¼ˆPDF 185-200é¡µï¼‰
   - ğŸ“– RAGç³»ç»Ÿï¼ˆPDF 220-260é¡µï¼‰

2. **è¿è¡Œé¡¹ç›®**:
   ```bash
   # æ™ºèƒ½é—®ç­”ç³»ç»Ÿ
   cd local-website-chatbot/
   npm install && npm run dev
   
   # è¯„è®ºåˆ†æ
   cd ../review-analyzer/
   python analyze.py
   ```

3. **å®æˆ˜ä»»åŠ¡**:
   - æ„å»ºHawaiiHubé—®ç­”æœºå™¨äºº
   - åˆ†æé¤å…è¯„è®ºæƒ…æ„Ÿ

---

## ğŸ› ï¸ è‡ªåŠ¨åŒ–è„šæœ¬å»ºè®®

### è„šæœ¬1: å…¨æ¨¡å—é‡‡é›†å™¨

```python
#!/usr/bin/env python3
"""
HawaiiHub å…¨æ¨¡å—æ•°æ®é‡‡é›†å™¨
åŸºäº Firecrawl å­¦ä¹ æ‰‹å†Œæœ€ä½³å®è·µ
"""

import json
import os
from datetime import datetime
from firecrawl import FirecrawlApp
from typing import List, Dict

# åŠ è½½é…ç½®
with open('config/hawaiihub_data_sources.json', 'r') as f:
    config = json.load(f)

app = FirecrawlApp(api_key=os.getenv("FIRECRAWL_API_KEY"))

def scrape_module(module_id: str, max_sources: int = 3) -> List[Dict]:
    """
    é‡‡é›†æŒ‡å®šæ¨¡å—çš„æ•°æ®
    
    Args:
        module_id: æ¨¡å—IDï¼ˆå¦‚ '1_rental_housing'ï¼‰
        max_sources: æœ€å¤šé‡‡é›†å‡ ä¸ªæºï¼ˆé»˜è®¤3ï¼‰
    
    Returns:
        é‡‡é›†ç»“æœåˆ—è¡¨
    """
    module = config['modules'][module_id]
    sources = module['sources'][:max_sources]
    
    results = []
    for source in sources:
        if source['data_quality'] != 'high':
            continue  # åªé‡‡é›†é«˜è´¨é‡æº
            
        try:
            print(f"ğŸ“¡ é‡‡é›†: {source['name']} - {source['url']}")
            
            result = app.scrape(
                url=source['url'],
                formats=["markdown"],
                only_main_content=True,
                max_age=get_cache_ttl(module_id)
            )
            
            results.append({
                "source_id": source['id'],
                "source_name": source['name'],
                "url": source['url'],
                "content": result.markdown,
                "scraped_at": datetime.now().isoformat()
            })
            
            print(f"âœ… æˆåŠŸ: {len(result.markdown)} å­—ç¬¦")
            
        except Exception as e:
            print(f"âŒ å¤±è´¥: {source['name']} - {e}")
            continue
    
    return results

def get_cache_ttl(module_id: str) -> int:
    """è·å–æ¨¡å—çš„ç¼“å­˜æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰"""
    ttl_map = {
        "1_rental_housing": 86400000,      # 1å¤©
        "2_dining_restaurants": 604800000,  # 7å¤©
        "3_jobs_employment": 43200000,      # 12å°æ—¶
        "4_community_events": 86400000,     # 1å¤©
        "5_news_media": 3600000,            # 1å°æ—¶
        "6_tourism_attractions": 2592000000,# 30å¤©
        "7_education": 2592000000,          # 30å¤©
        "8_healthcare": 2592000000,         # 30å¤©
        "9_shopping_lifestyle": 604800000,  # 7å¤©
        "10_transportation": 604800000      # 7å¤©
    }
    return ttl_map.get(module_id, 86400000)

# ä¸»ç¨‹åº
if __name__ == "__main__":
    print("ğŸš€ HawaiiHub æ•°æ®é‡‡é›†å¯åŠ¨...")
    
    # é‡‡é›†P0ä¼˜å…ˆçº§æ¨¡å—
    p0_modules = ["1_rental_housing", "2_dining_restaurants", "5_news_media"]
    
    for module_id in p0_modules:
        print(f"\n{'='*60}")
        print(f"ğŸ“¦ æ¨¡å—: {config['modules'][module_id]['name']}")
        print(f"{'='*60}")
        
        results = scrape_module(module_id, max_sources=3)
        
        # ä¿å­˜æ•°æ®
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"data/scraped/{module_id}_{timestamp}.json"
        
        os.makedirs("data/scraped", exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ å·²ä¿å­˜: {output_file}")
    
    print("\nâœ… å…¨éƒ¨é‡‡é›†å®Œæˆï¼")
```

ä¿å­˜åˆ°: `scripts/scrape_all_modules.py`

---

### è„šæœ¬2: æˆæœ¬ç›‘æ§å™¨

```python
#!/usr/bin/env python3
"""
Firecrawl æˆæœ¬ç›‘æ§å™¨
å‚è€ƒå­¦ä¹ æ‰‹å†Œï¼šæˆæœ¬æ§åˆ¶æœ€ä½³å®è·µ
"""

class FirecrawlCostMonitor:
    """æˆæœ¬ç›‘æ§å™¨ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†Œæ¡ˆä¾‹14ï¼‰"""
    
    def __init__(self, daily_budget: float = 10.0):
        self.daily_budget = daily_budget
        self.requests_today = 0
        self.cost_today = 0.0
        self.cost_per_request = 0.01
        
    def log_request(self, url: str, credits_used: int = 1):
        """è®°å½•æ¯æ¬¡è¯·æ±‚"""
        cost = credits_used * self.cost_per_request
        self.requests_today += 1
        self.cost_today += cost
        
        print(f"ğŸ“Š è¯·æ±‚#{self.requests_today} | "
              f"æˆæœ¬: ${cost:.4f} | "
              f"ç´¯è®¡: ${self.cost_today:.2f}/{self.daily_budget}")
        
        # é¢„ç®—å‘Šè­¦
        if self.cost_today >= self.daily_budget * 0.8:
            print(f"âš ï¸ è­¦å‘Šï¼šå·²ä½¿ç”¨ {self.cost_today/self.daily_budget*100:.1f}% é¢„ç®—ï¼")
        
        return cost
    
    def get_daily_report(self) -> Dict:
        """ç”Ÿæˆæ¯æ—¥æŠ¥å‘Š"""
        return {
            "date": datetime.now().date().isoformat(),
            "total_requests": self.requests_today,
            "total_cost": self.cost_today,
            "budget_used_pct": self.cost_today / self.daily_budget * 100,
            "remaining_budget": self.daily_budget - self.cost_today
        }
```

ä¿å­˜åˆ°: `src/cost_monitor.py`

---

## âš ï¸ é‡è¦æé†’ï¼ˆåŸºäºå­¦ä¹ æ‰‹å†Œç»éªŒï¼‰

### 1. é¿å…å¸¸è§é”™è¯¯

âŒ **é”™è¯¯1**: ä¸æ£€æŸ¥ç¼“å­˜ç›´æ¥çˆ¬å–
```python
# é”™è¯¯
result = app.scrape(url)  # æ¯æ¬¡éƒ½é‡æ–°çˆ¬å–

# æ­£ç¡®
result = app.scrape(url, max_age=172800000)  # 2å¤©ç¼“å­˜
```

âŒ **é”™è¯¯2**: ä¸²è¡Œå¤„ç†å¤§é‡URL
```python
# é”™è¯¯ï¼ˆæ…¢ï¼‰
for url in urls:
    result = app.scrape(url)

# æ­£ç¡®ï¼ˆå¿«ï¼‰
results = app.batch_scrape(urls, formats=["markdown"])
```

âŒ **é”™è¯¯3**: å¿½ç•¥é”™è¯¯å¤„ç†
```python
# é”™è¯¯
result = app.scrape(url)  # å¯èƒ½å´©æºƒ

# æ­£ç¡®ï¼ˆå‚è€ƒå­¦ä¹ æ‰‹å†Œé”™è¯¯å¤„ç†ï¼‰
try:
    result = app.scrape(url, formats=["markdown"], only_main_content=True)
except RequestTimeoutError:
    # é‡è¯•é€»è¾‘
    pass
except Exception as e:
    logging.error(f"é‡‡é›†å¤±è´¥: {e}")
```

---

### 2. æœ€ä½³å®è·µï¼ˆå­¦ä¹ æ‰‹å†Œæ€»ç»“ï¼‰

âœ… **å®è·µ1**: å…ˆMapï¼ŒåCrawl/Scrape
```python
# 1. å‘ç°URL
urls = app.map(url="https://example.com")
# 2. æ‰¹é‡é‡‡é›†
results = app.batch_scrape(urls['links'][:100])
```

âœ… **å®è·µ2**: ä½¿ç”¨Extractè‡ªåŠ¨æå–
```python
# æ— éœ€æ‰‹åŠ¨è§£æï¼ŒLLMè‡ªåŠ¨æå–
data = app.extract(urls=[url], schema=your_schema)
```

âœ… **å®è·µ3**: ç›‘æ§å˜æ›´èŠ‚çœæˆæœ¬
```python
# åªé‡‡é›†å˜åŒ–çš„é¡µé¢
app.scrape(url, formats=["changeTracking"])
```

---

## ğŸ“– å­¦ä¹ èµ„æºè·¯å¾„

### ç«‹å³é˜…è¯»ï¼ˆä¼˜å…ˆçº§æ’åºï¼‰

1. **ğŸš€ å¿«é€Ÿå¼€å§‹**ï¼ˆ5åˆ†é’Ÿï¼‰
   ```bash
   open "/Users/zhiledeng/Downloads/FireShot/Firecrawlå­¦ä¹ æ‰‹å†Œ/ğŸš€å¿«é€Ÿä½¿ç”¨æŒ‡å—.md"
   ```

2. **ğŸ“‹ å®Œæ•´æ‰‹å†Œ**ï¼ˆ1.5å°æ—¶ï¼‰
   ```bash
   open "/Users/zhiledeng/Downloads/FireShot/Firecrawlå­¦ä¹ æ‰‹å†Œ/01-åŸºç¡€å…¥é—¨/Firecrawlå®Œæ•´å­¦ä¹ æ‰‹å†Œ.md"
   ```

3. **ğŸ’¼ HawaiiHubæ¡ˆä¾‹**ï¼ˆ2å°æ—¶ï¼‰
   ```bash
   cd "/Users/zhiledeng/Downloads/FireShot/Firecrawlå­¦ä¹ æ‰‹å†Œ/05-å®æˆ˜æ¡ˆä¾‹"
   open "HawaiiHubå®æˆ˜æ¡ˆä¾‹æ‰‹å†Œ.md"
   ```

4. **ğŸ“¦ 96ä¸ªé¡¹ç›®ç´¢å¼•**ï¼ˆ30åˆ†é’Ÿï¼‰
   ```bash
   open "/Users/zhiledeng/Downloads/FireShot/Firecrawlå­¦ä¹ æ‰‹å†Œ/05-å®æˆ˜æ¡ˆä¾‹/å®Œæ•´é¡¹ç›®æ€»ç´¢å¼•.md"
   ```

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### âœ… ç«‹å³æ‰§è¡Œï¼ˆä»Šå¤©ï¼‰

1. **é˜…è¯»å¿«é€ŸæŒ‡å—**ï¼ˆ15åˆ†é’Ÿï¼‰
   ```bash
   open "/Users/zhiledeng/Downloads/FireShot/Firecrawlå­¦ä¹ æ‰‹å†Œ/ğŸš€å¿«é€Ÿä½¿ç”¨æŒ‡å—.md"
   ```

2. **æŸ¥çœ‹Top10æ¨èé¡¹ç›®**ï¼ˆ30åˆ†é’Ÿï¼‰
   ```bash
   cd "/Users/zhiledeng/Downloads/FireShot/Firecrawlå­¦ä¹ æ‰‹å†Œ/05-å®æˆ˜æ¡ˆä¾‹/ç¤ºä¾‹åº”ç”¨/firecrawl-app-examples"
   
   # æŸ¥çœ‹Top1é¡¹ç›®
   cd company-data-scraper/
   cat README.md
   ```

3. **æµ‹è¯•é‡‡é›†ç§Ÿæˆ¿æ¨¡å—**ï¼ˆ1å°æ—¶ï¼‰
   ```bash
   cd /Users/zhiledeng/Downloads/FireShot
   python3 scripts/scrape_all_modules.py
   ```

---

### ğŸ“… æœ¬å‘¨è®¡åˆ’

- **å‘¨ä¸€**: ç§Ÿæˆ¿æ¨¡å—ï¼ˆ50ä¸ªæˆ¿æºï¼‰
- **å‘¨äºŒ**: é¤é¥®æ¨¡å—ï¼ˆ100ä¸ªé¤å…ï¼‰
- **å‘¨ä¸‰**: å°±ä¸šæ¨¡å—ï¼ˆ200ä¸ªèŒä½ï¼‰
- **å‘¨å››**: æ–°é—»æ¨¡å—ï¼ˆå®æ—¶é‡‡é›†ï¼‰
- **å‘¨äº”**: å…¶ä»–æ¨¡å—ï¼ˆå¿«é€Ÿæ‰«æï¼‰

---

### ğŸ“Š æœ¬æœˆç›®æ ‡

- âœ… å®Œæˆ100ä¸ªä¿¡æ¯æºçš„é¦–æ¬¡é‡‡é›†
- âœ… å»ºç«‹è‡ªåŠ¨åŒ–é‡‡é›†æµç¨‹
- âœ… å®ç°æ•°æ®è´¨é‡ç›‘æ§
- âœ… éƒ¨ç½²3ä¸ªAIåº”ç”¨ï¼ˆé—®ç­”ã€æ¨èã€ç›‘æ§ï¼‰

---

## ğŸ† é¢„æœŸæˆæœ

é€šè¿‡**Firecrawlå­¦ä¹ æ‰‹å†Œ**çš„æŒ‡å¯¼å’Œ**100ä¸ªä¼˜è´¨ä¿¡æ¯æº**ï¼Œæ‚¨å°†è·å¾—ï¼š

1. **æ•°æ®èµ„äº§**:
   - 1,000+ ç§Ÿæˆ¿ä¿¡æ¯
   - 500+ é¤å…ä¿¡æ¯
   - 2,000+ æ‹›è˜èŒä½
   - æ¯æ—¥æ–°é—»æ›´æ–°

2. **æŠ€æœ¯èƒ½åŠ›**:
   - æŒæ¡Firecrawlå…¨æ ˆæŠ€èƒ½
   - èƒ½æ„å»ºAIé©±åŠ¨åº”ç”¨
   - èƒ½è®¾è®¡ä¼ä¸šçº§æ¶æ„

3. **å•†ä¸šä»·å€¼**:
   - HawaiiHubæ•°æ®å®Œæ•´æ€§
   - ç”¨æˆ·ä½“éªŒæå‡
   - è¿è¥æ•ˆç‡æé«˜

---

**åˆ›å»ºæ—¶é—´**: 2025-10-28  
**åŸºäº**: Firecrawlå­¦ä¹ æ‰‹å†Œ v2.0 + 100ä¸ªä¼˜è´¨ä¿¡æ¯æº  
**ç»´æŠ¤è€…**: HawaiiHub AI Team
