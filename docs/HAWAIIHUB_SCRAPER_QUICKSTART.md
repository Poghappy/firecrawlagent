# HawaiiHub æ•°æ®é‡‡é›†å¿«é€Ÿä¸Šæ‰‹æŒ‡å—

> **ç”Ÿæˆæ—¶é—´**: 2025-10-28
> **ç‰ˆæœ¬**: v1.0
> **å‰ç½®æ–‡æ¡£**: [HAWAIIHUB_DATA_SOURCES_CATALOG.md](HAWAIIHUB_DATA_SOURCES_CATALOG.md)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ï¼ˆ5åˆ†é’Ÿï¼‰

### 1. æ£€æŸ¥ç¯å¢ƒ

```bash
# ç¡®è®¤ Python ç‰ˆæœ¬ >= 3.11
python3 --version

# ç¡®è®¤å·²å®‰è£… Firecrawl SDK
python3 -c "import firecrawl; print('Firecrawl SDK å·²å®‰è£…')"
```

### 2. é…ç½® API å¯†é’¥

```bash
# ç¼–è¾‘ .env æ–‡ä»¶
nano .env

# æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼ˆæ›¿æ¢ä¸ºä½ çš„çœŸå®å¯†é’¥ï¼‰
FIRECRAWL_API_KEY=fc-xxxxxxxxxxxxxxxx
```

### 3. æµ‹è¯•é‡‡é›†

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd /Users/zhiledeng/Downloads/FireShot

# åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®æº
python3 scripts/hawaiihub_scraper.py --list

# é‡‡é›†å•ä¸ªæ–°é—»æºï¼ˆæµ‹è¯•ï¼‰
python3 scripts/hawaiihub_scraper.py --source "Hawaii News Now"
```

### 4. æŸ¥çœ‹ç»“æœ

```bash
# æŸ¥çœ‹ JSON ç»“æœ
ls -lh data/hawaiihub/*.json

# æŸ¥çœ‹ Markdown ç»“æœ
cat data/hawaiihub/single_source_news_*.md

# æŸ¥çœ‹æ—¥å¿—
tail -f logs/hawaiihub_scraper.log
```

---

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: é‡‡é›†æ‰€æœ‰æ–°é—»æº

```bash
python3 scripts/hawaiihub_scraper.py --category news
```

**è¾“å‡º**:

```
å¼€å§‹é‡‡é›†: Hawaii News Now (https://www.hawaiinewsnow.com/)
é‡‡é›†æˆåŠŸ: Hawaii News Now | è¯·æ±‚ #1 | æˆæœ¬: $0.01
å¼€å§‹é‡‡é›†: Honolulu Civil Beat (https://www.civilbeat.org/)
é‡‡é›†æˆåŠŸ: Honolulu Civil Beat | è¯·æ±‚ #2 | æˆæœ¬: $0.02
...

ğŸ“Š é‡‡é›†ç»Ÿè®¡
============================================================
æ€»è¯·æ±‚æ•°: 4
æˆåŠŸæ•°: 4
å¤±è´¥æ•°: 0
æˆåŠŸç‡: 100.0%
æ€»æˆæœ¬: $0.04
============================================================
```

**ç”Ÿæˆæ–‡ä»¶**:

- `data/hawaiihub/category_news_20251028_191234.json` - JSON æ ¼å¼
- `data/hawaiihub/category_news_news_20251028_191234.md` - Markdown æ ¼å¼

### ç¤ºä¾‹2: é‡‡é›†åäººç¤¾åŒºèµ„æº

```bash
python3 scripts/hawaiihub_scraper.py --category chinese_community
```

**ç”¨é€”**: è·å–åäººç¤¾åŒºæœ€æ–°æ´»åŠ¨ã€æ–°é—»ã€å•†ä¸šä¿¡æ¯

### ç¤ºä¾‹3: é‡‡é›† P0 ä¼˜å…ˆçº§æ•°æ®ï¼ˆæ ¸å¿ƒæ—¥å¸¸ï¼‰

```bash
python3 scripts/hawaiihub_scraper.py --priority P0
```

**ç”¨é€”**: æ‰§è¡Œæ¯æ—¥æ ¸å¿ƒé‡‡é›†ä»»åŠ¡ï¼ˆæ–°é—» + åäººç¤¾åŒº + é¤é¥®ï¼‰

### ç¤ºä¾‹4: é‡‡é›†æ‰€æœ‰æ•°æ®æºï¼ˆè°¨æ…ä½¿ç”¨ï¼‰

```bash
python3 scripts/hawaiihub_scraper.py --all
```

**è­¦å‘Š**:

- å°†é‡‡é›†æ‰€æœ‰ 45 ä¸ªæ•°æ®æº
- é¢„è®¡è€—æ—¶: 5-10 åˆ†é’Ÿ
- é¢„è®¡æˆæœ¬: $0.45ï¼ˆ45ä¸ªè¯·æ±‚ Ã— $0.01ï¼‰

### ç¤ºä¾‹5: é‡‡é›†å•ä¸ªç‰¹å®šæ•°æ®æº

```bash
# é‡‡é›†å¤å¨å¤·ä¸­å›½æ—¥æŠ¥
python3 scripts/hawaiihub_scraper.py --source "å¤å¨å¤·ä¸­å›½æ—¥æŠ¥"

# é‡‡é›† Yelp é¤å…ä¿¡æ¯
python3 scripts/hawaiihub_scraper.py --source "Yelp Honolulu Hawaiian"
```

---

## ğŸ“‚ æ•°æ®æ–‡ä»¶ç»“æ„

é‡‡é›†å®Œæˆåï¼Œæ•°æ®ä¿å­˜åœ¨ `data/hawaiihub/` ç›®å½•ï¼š

```
data/hawaiihub/
â”œâ”€â”€ category_news_20251028_191234.json          # JSON æ ¼å¼ï¼ˆç¨‹åºå¤„ç†ï¼‰
â”œâ”€â”€ category_news_news_20251028_191234.md       # Markdown æ ¼å¼ï¼ˆäººç±»é˜…è¯»ï¼‰
â”œâ”€â”€ priority_P0_20251028_192000.json
â”œâ”€â”€ priority_P0_news_20251028_192000.md
â”œâ”€â”€ priority_P0_chinese_community_20251028_192000.md
â””â”€â”€ all_sources_20251028_193000.json
```

### JSON æ•°æ®æ ¼å¼

```json
[
  {
    "source_name": "Hawaii News Now",
    "source_url": "https://www.hawaiinewsnow.com/",
    "category": "news",
    "priority": "P0",
    "content": "# Hawaii News Now\n\n## Breaking News...",
    "metadata": {
      "title": "Hawaii News Now - Breaking News",
      "description": "..."
    },
    "scraped_at": "2025-10-28T19:12:34.567890"
  }
]
```

### Markdown æ•°æ®æ ¼å¼

```markdown
# NEWS é‡‡é›†ç»“æœ

> é‡‡é›†æ—¶é—´: 2025-10-28 19:12:34
> æ•°æ®æºæ•°é‡: 4

---

## Hawaii News Now

- **URL**: https://www.hawaiinewsnow.com/
- **ä¼˜å…ˆçº§**: P0
- **é‡‡é›†æ—¶é—´**: 2025-10-28T19:12:34.567890

### å†…å®¹

# Hawaii News Now

Breaking news from Hawaii...

---
```

---

## â° å®šæ—¶é‡‡é›†ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰

### æ–¹å¼1: ä½¿ç”¨ cronï¼ˆæ¨èï¼‰

```bash
# ç¼–è¾‘ crontab
crontab -e

# æ·»åŠ ä»¥ä¸‹ä»»åŠ¡
# æ¯2å°æ—¶é‡‡é›† P0 æ–°é—»
0 */2 * * * cd /Users/zhiledeng/Downloads/FireShot && python3 scripts/hawaiihub_scraper.py --category news >> logs/cron.log 2>&1

# æ¯6å°æ—¶é‡‡é›†åäººç¤¾åŒº
0 */6 * * * cd /Users/zhiledeng/Downloads/FireShot && python3 scripts/hawaiihub_scraper.py --category chinese_community >> logs/cron.log 2>&1

# æ¯å¤©æ—©ä¸Š10ç‚¹é‡‡é›†é¤å…ä¿¡æ¯
0 10 * * * cd /Users/zhiledeng/Downloads/FireShot && python3 scripts/hawaiihub_scraper.py --category restaurant >> logs/cron.log 2>&1

# æ¯å‘¨ä¸€æ—©ä¸Š8ç‚¹é‡‡é›†æ´»åŠ¨æ—¥å†
0 8 * * 1 cd /Users/zhiledeng/Downloads/FireShot && python3 scripts/hawaiihub_scraper.py --category events >> logs/cron.log 2>&1

# æ¯æœˆ1å·å‡Œæ™¨2ç‚¹é‡‡é›†å•†ä¸šç›®å½•
0 2 1 * * cd /Users/zhiledeng/Downloads/FireShot && python3 scripts/hawaiihub_scraper.py --category business >> logs/cron.log 2>&1
```

### æ–¹å¼2: ä½¿ç”¨ launchdï¼ˆmacOS æ¨èï¼‰

åˆ›å»º `~/Library/LaunchAgents/com.hawaiihub.scraper.plist`:

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>Label</key>
    <string>com.hawaiihub.scraper</string>
    <key>ProgramArguments</key>
    <array>
        <string>/usr/bin/python3</string>
        <string>/Users/zhiledeng/Downloads/FireShot/scripts/hawaiihub_scraper.py</string>
        <string>--priority</string>
        <string>P0</string>
    </array>
    <key>StartInterval</key>
    <integer>7200</integer> <!-- æ¯2å°æ—¶ -->
    <key>StandardOutPath</key>
    <string>/Users/zhiledeng/Downloads/FireShot/logs/scraper.out.log</string>
    <key>StandardErrorPath</key>
    <string>/Users/zhiledeng/Downloads/FireShot/logs/scraper.err.log</string>
</dict>
</plist>
```

åŠ è½½ä»»åŠ¡:

```bash
launchctl load ~/Library/LaunchAgents/com.hawaiihub.scraper.plist
launchctl list | grep hawaiihub
```

---

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰æ•°æ®æº

ç¼–è¾‘ `scripts/hawaiihub_scraper.py`ï¼Œæ·»åŠ æ–°çš„æ•°æ®æºï¼š

```python
CUSTOM_SOURCES = [
    {
        "name": "ä½ çš„æ•°æ®æºåç§°",
        "url": "https://example.com",
        "category": "custom",
        "priority": "P1",
        "frequency": "0 12 * * *",  # æ¯å¤©ä¸­åˆ12ç‚¹
        "scrape_config": {
            "formats": ["markdown"],
            "only_main_content": True,
            "max_age": 86400000  # 24å°æ—¶ç¼“å­˜
        }
    }
]

# æ·»åŠ åˆ° ALL_SOURCES
ALL_SOURCES = (
    NEWS_SOURCES +
    CHINESE_COMMUNITY_SOURCES +
    RESTAURANT_SOURCES +
    EVENT_SOURCES +
    BUSINESS_SOURCES +
    CUSTOM_SOURCES  # æ–°å¢
)
```

### æˆæœ¬æ§åˆ¶

```python
# åœ¨ HawaiiHubScraper.__init__ ä¸­æ·»åŠ é¢„ç®—é™åˆ¶
def __init__(self, api_key: Optional[str] = None, daily_budget: float = 10.0):
    self.daily_budget = daily_budget

    # åœ¨ scrape_source ä¸­æ£€æŸ¥é¢„ç®—
    if self.total_cost >= self.daily_budget:
        raise BudgetExceededError(f"è¶…å‡ºæ¯æ—¥é¢„ç®—: ${self.daily_budget}")
```

### é”™è¯¯é‡è¯•

```python
def scrape_source_with_retry(self, source: Dict, max_retries: int = 3) -> Optional[Dict]:
    """å¸¦é‡è¯•çš„é‡‡é›†"""
    for attempt in range(max_retries):
        try:
            return self.scrape_source(source)
        except Exception as e:
            if attempt < max_retries - 1:
                wait_time = 2 ** attempt
                logger.warning(f"é‡è¯• {attempt+1}/{max_retries}ï¼Œç­‰å¾… {wait_time}ç§’...")
                time.sleep(wait_time)
            else:
                logger.error(f"å¤±è´¥ï¼ˆ{max_retries}æ¬¡é‡è¯•åï¼‰: {e}")
                return None
```

---

## ğŸ“Š æ•°æ®å¤„ç†æµç¨‹

### 1. é‡‡é›† â†’ 2. æ¸…æ´— â†’ 3. å­˜å‚¨ â†’ 4. åˆ†æ

```bash
# 1. é‡‡é›†åŸå§‹æ•°æ®
python3 scripts/hawaiihub_scraper.py --category news

# 2. æ¸…æ´—æ•°æ®ï¼ˆTODO: åˆ›å»ºæ¸…æ´—è„šæœ¬ï¼‰
python3 scripts/clean_scraped_data.py data/hawaiihub/category_news_*.json

# 3. å¯¼å…¥æ•°æ®åº“ï¼ˆTODO: åˆ›å»ºå¯¼å…¥è„šæœ¬ï¼‰
python3 scripts/import_to_database.py data/hawaiihub/cleaned_*.json

# 4. ç”Ÿæˆåˆ†ææŠ¥å‘Šï¼ˆTODO: åˆ›å»ºåˆ†æè„šæœ¬ï¼‰
python3 scripts/analyze_data.py --category news --date-range 7days
```

---

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜1: é€Ÿç‡é™åˆ¶é”™è¯¯

```
Error: Rate limit exceeded. Consumed (req/min): 6, Remaining (req/min): 0
```

**è§£å†³æ–¹æ¡ˆ**:

- ç­‰å¾…1åˆ†é’Ÿåé‡è¯•
- åœ¨è„šæœ¬ä¸­å¢åŠ  `time.sleep(2)` å»¶è¿Ÿ
- ä½¿ç”¨å¤šä¸ª API å¯†é’¥è½®æ¢

### é—®é¢˜2: API å¯†é’¥æ— æ•ˆ

```
Error: æœªæ‰¾åˆ° FIRECRAWL_API_KEYï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# æ£€æŸ¥ .env æ–‡ä»¶
cat .env | grep FIRECRAWL_API_KEY

# æ‰‹åŠ¨è®¾ç½®ç¯å¢ƒå˜é‡
export FIRECRAWL_API_KEY=fc-xxxxxxxxxxxxxxxx

# æµ‹è¯• API å¯†é’¥
python3 test_api_keys.py
```

### é—®é¢˜3: é‡‡é›†è¶…æ—¶

```
Error: Request timeout after 60 seconds
```

**è§£å†³æ–¹æ¡ˆ**:

- æ£€æŸ¥ç½‘ç»œè¿æ¥
- å¢åŠ è¶…æ—¶æ—¶é—´ï¼ˆåœ¨ scrape_config ä¸­æ·»åŠ  `timeout: 120`ï¼‰
- ä½¿ç”¨ `max_age` å‚æ•°åˆ©ç”¨ç¼“å­˜

### é—®é¢˜4: å†…å®¹ä¸ºç©º

```
Warning: é‡‡é›†ç»“æœä¸ºç©º
```

**è§£å†³æ–¹æ¡ˆ**:

- æ£€æŸ¥ç›®æ ‡ç½‘ç«™æ˜¯å¦å¯è®¿é—®
- å°è¯•ç§»é™¤ `only_main_content: True`
- æŸ¥çœ‹ç½‘ç«™æ˜¯å¦éœ€è¦ç™»å½•æˆ–æœ‰åçˆ¬è™«æœºåˆ¶

---

## ğŸ“ˆ ç›‘æ§ä¸å‘Šè­¦

### å®æ—¶ç›‘æ§

```bash
# ç›‘æ§æ—¥å¿—
tail -f logs/hawaiihub_scraper.log

# ç»Ÿè®¡æˆåŠŸç‡
grep "é‡‡é›†æˆåŠŸ" logs/hawaiihub_scraper.log | wc -l
grep "é‡‡é›†å¤±è´¥" logs/hawaiihub_scraper.log | wc -l

# æŸ¥çœ‹æˆæœ¬
grep "æ€»æˆæœ¬" logs/hawaiihub_scraper.log | tail -1
```

### æˆæœ¬è·Ÿè¸ª

åˆ›å»º `scripts/cost_tracker.sh`:

```bash
#!/bin/bash

# ç»Ÿè®¡æ¯æ—¥æˆæœ¬
LOG_FILE="logs/hawaiihub_scraper.log"
TODAY=$(date +%Y-%m-%d)

echo "ğŸ“Š æ¯æ—¥æˆæœ¬ç»Ÿè®¡ - $TODAY"
echo "================================"

# æå–ä»Šæ—¥çš„æˆæœ¬è®°å½•
grep "$TODAY" "$LOG_FILE" | grep "æ€»æˆæœ¬" | tail -1

# æå–è¯·æ±‚æ•°
REQUEST_COUNT=$(grep "$TODAY" "$LOG_FILE" | grep "è¯·æ±‚" | wc -l)
echo "æ€»è¯·æ±‚æ•°: $REQUEST_COUNT"

# é¢„ä¼°æˆæœ¬
ESTIMATED_COST=$(echo "$REQUEST_COUNT * 0.01" | bc)
echo "é¢„ä¼°æˆæœ¬: \$$ESTIMATED_COST"
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. åˆ†é˜¶æ®µé‡‡é›†ï¼ˆæ¨èï¼‰

```bash
# ç¬¬ä¸€å‘¨ï¼šåªé‡‡é›† P0 æ•°æ®æº
python3 scripts/hawaiihub_scraper.py --priority P0

# ç¬¬äºŒå‘¨ï¼šå¢åŠ  P1 æ•°æ®æº
python3 scripts/hawaiihub_scraper.py --priority P1

# ç¬¬ä¸‰å‘¨ï¼šå…¨é‡é‡‡é›†
python3 scripts/hawaiihub_scraper.py --all
```

### 2. ä½¿ç”¨ç¼“å­˜èŠ‚çœæˆæœ¬

```python
# åˆ©ç”¨ Firecrawl çš„ç¼“å­˜æœºåˆ¶
scrape_config = {
    "formats": ["markdown"],
    "only_main_content": True,
    "max_age": 172800000  # 2å¤©ç¼“å­˜ï¼ŒèŠ‚çœ 50%+ æˆæœ¬
}
```

### 3. æ‰¹é‡é‡‡é›†

```python
# ä½¿ç”¨ batch_scrapeï¼ˆæ›´é«˜æ•ˆï¼‰
urls = [source["url"] for source in NEWS_SOURCES]
results = app.batch_scrape(urls=urls, formats=["markdown"])
```

### 4. å¢é‡æ›´æ–°

```python
# åªçˆ¬å–æ–°å†…å®¹
def scrape_incremental(category: str, since: datetime):
    """å¢é‡é‡‡é›†ï¼ˆåªè·å–æŒ‡å®šæ—¶é—´åçš„æ–°å†…å®¹ï¼‰"""
    # å®ç°é€»è¾‘...
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [HAWAIIHUB_DATA_SOURCES_CATALOG.md](HAWAIIHUB_DATA_SOURCES_CATALOG.md) - å®Œæ•´æ•°æ®æºæ¸…å•
- [Firecrawl äº‘ç«¯ API è§„èŒƒ](../Firecrawlå­¦ä¹ æ‰‹å†Œ/03-APIå‚è€ƒ/äº‘ç«¯APIè§„èŒƒ.md)
- [Firecrawl äº‘ç«¯é…ç½®æŒ‡å—](../Firecrawlå­¦ä¹ æ‰‹å†Œ/04-é…ç½®æŒ‡å—/äº‘ç«¯é…ç½®æŒ‡å—.md)

---

## ğŸ†˜ è·å–å¸®åŠ©

### å¸¸è§é—®é¢˜

- **Q: å¦‚ä½•æ·»åŠ æ–°çš„æ•°æ®æºï¼Ÿ**
  A: ç¼–è¾‘ `scripts/hawaiihub_scraper.py`ï¼Œåœ¨å¯¹åº”çš„ `*_SOURCES` åˆ—è¡¨ä¸­æ·»åŠ é…ç½®

- **Q: å¦‚ä½•ä¿®æ”¹é‡‡é›†é¢‘ç‡ï¼Ÿ**
  A: ä¿®æ”¹ crontab æˆ– launchd é…ç½®æ–‡ä»¶ä¸­çš„æ—¶é—´è¡¨è¾¾å¼

- **Q: å¦‚ä½•æŸ¥çœ‹å†å²é‡‡é›†è®°å½•ï¼Ÿ**
  A: æŸ¥çœ‹ `data/hawaiihub/` ç›®å½•ä¸‹çš„ JSON å’Œ Markdown æ–‡ä»¶

- **Q: å¦‚ä½•å¯¼å‡ºæ•°æ®åˆ°æ•°æ®åº“ï¼Ÿ**
  A: å‚è€ƒ [æ•°æ®å¤„ç†æµç¨‹](#æ•°æ®å¤„ç†æµç¨‹) ç« èŠ‚ï¼ˆéœ€è¦é¢å¤–å¼€å‘ï¼‰

### è”ç³»æ–¹å¼

- **é¡¹ç›®ç»´æŠ¤**: HawaiiHub AI Team
- **æŠ€æœ¯æ”¯æŒ**: Firecrawl Discord (https://discord.gg/firecrawl)
- **é—®é¢˜åé¦ˆ**: GitHub Issues

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-10-28
**ç»´æŠ¤è€…**: HawaiiHub AI Team
