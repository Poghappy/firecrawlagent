# ğŸ”¥ Firecrawl å®˜æ–¹æ¨¡æ¿å®Œæ•´ç›®å½•

> **æœ€åæ›´æ–°**: 2025-10-28
> **æ¥æº**: Firecrawl å®˜æ–¹æ–‡æ¡£ + GitHub ä¸»ä»“åº“
> **æ€»è®¡**: 55+ æ¨¡æ¿ï¼ˆä»£ç ç‰‡æ®µ + å…¨æ ˆé¡¹ç›®ï¼‰

---

## ğŸ“‹ ç›®å½•æ¦‚è§ˆ

### ğŸ“¦ ä»£ç ç‰‡æ®µåˆ†ç±»ï¼ˆæŒ‰åŠŸèƒ½ï¼‰

- **Scrapeï¼ˆå•é¡µçˆ¬å–ï¼‰**: 15+ æ¨¡æ¿
- **Crawlï¼ˆç½‘ç«™çˆ¬å–ï¼‰**: 10+ æ¨¡æ¿
- **Mapï¼ˆç½‘ç«™åœ°å›¾ï¼‰**: 5+ æ¨¡æ¿
- **Searchï¼ˆæœç´¢ï¼‰**: 5+ æ¨¡æ¿
- **Batch Scrapeï¼ˆæ‰¹é‡çˆ¬å–ï¼‰**: 8+ æ¨¡æ¿
- **Extractï¼ˆæ•°æ®æå–ï¼‰**: 8+ æ¨¡æ¿
- **Webhookï¼ˆäº‹ä»¶é€šçŸ¥ï¼‰**: 6+ æ¨¡æ¿
- **å¼‚æ­¥æ“ä½œ**: 4+ æ¨¡æ¿

### ğŸ—ï¸ å…¨æ ˆé¡¹ç›®æ¨¡æ¿ï¼ˆ9ä¸ªï¼‰

- Open Lovable - RAG èŠå¤©æœºå™¨äºº
- Open Agent Builder - AI ä»£ç†æ„å»ºå™¨
- Fireplexity - AI æœç´¢å¼•æ“
- FireGEO - SaaS å“ç‰Œç›‘æ§
- Fire Enrich - æ•°æ®ä¸°å¯ŒåŒ–å·¥å…·
- Firesearch - æ·±åº¦ç ”ç©¶å·¥å…·
- Firestarter - ç½‘ç«™èŠå¤©æœºå™¨äºº
- AI Ready Website - ç½‘ç«™ç»“æ„åŒ–è½¬æ¢
- Open Researcher - AI ç ”ç©¶åŠ©æ‰‹

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½æ¨¡æ¿è¯¦è§£

### 1ï¸âƒ£ Scrapeï¼ˆå•é¡µçˆ¬å–ï¼‰

#### åŸºç¡€çˆ¬å–

```python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key="fc-YOUR-API-KEY")

# åŸºç¡€çˆ¬å– - è¿”å› Markdown å’Œ HTML
doc = firecrawl.scrape(
    "https://firecrawl.dev",
    formats=["markdown", "html"]
)
print(doc.markdown)
```

**é€‚ç”¨åœºæ™¯**:

- å•ä¸ªç½‘é¡µå†…å®¹æå–
- æ–°é—»æ–‡ç« çˆ¬å–
- äº§å“è¯¦æƒ…é¡µé‡‡é›†
- åšå®¢æ–‡ç« è·å–

#### JSON ç»“æ„åŒ–æå–

```python
# å®šä¹‰æ•°æ®ç»“æ„
schema = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "author": {"type": "string"},
        "price": {"type": "number"},
        "rating": {"type": "number"}
    },
    "required": ["title", "author"]
}

# çˆ¬å–å¹¶æå–ç»“æ„åŒ–æ•°æ®
doc = firecrawl.scrape(
    "https://example.com/product",
    formats=[{
        "type": "json",
        "schema": schema
    }]
)

print(doc.extract)  # ç»“æ„åŒ–çš„ JSON æ•°æ®
```

**é€‚ç”¨åœºæ™¯**:

- ç”µå•†äº§å“ä¿¡æ¯æå–
- é¤å…ä¿¡æ¯é‡‡é›†ï¼ˆYelpã€Google Mapsï¼‰
- æ‹›è˜ä¿¡æ¯ç»“æ„åŒ–
- æˆ¿å±‹ç§Ÿèµä¿¡æ¯

#### æˆªå›¾æ¨¡å¼

```python
# çˆ¬å–é¡µé¢å¹¶ç”Ÿæˆæˆªå›¾
doc = firecrawl.scrape(
    "https://example.com",
    formats=[{
        "type": "screenshot",
        "fullPage": True,
        "quality": 90
    }]
)

# ä¿å­˜æˆªå›¾
with open("screenshot.png", "wb") as f:
    f.write(doc.screenshot)
```

**é€‚ç”¨åœºæ™¯**:

- é¡µé¢å¿«ç…§å­˜æ¡£
- UI/UX ç›‘æ§
- è§†è§‰å›å½’æµ‹è¯•
- åˆè§„æ€§è¯æ®

#### ä»£ç†æ¨¡å¼

```python
# ä½¿ç”¨ä»£ç†çˆ¬å–ï¼ˆç»•è¿‡åœ°ç†é™åˆ¶ï¼‰
doc = firecrawl.scrape(
    "https://example.com",
    formats=["markdown"],
    location={"country": "US"}
)
```

**é€‚ç”¨åœºæ™¯**:

- åœ°ç†é™åˆ¶å†…å®¹
- IP å°ç¦è§„é¿
- æœ¬åœ°åŒ–å†…å®¹æµ‹è¯•
- å¤šåœ°åŒºæ•°æ®é‡‡é›†

#### å¿«é€Ÿæ¨¡å¼

```python
# å¿«é€Ÿçˆ¬å–ï¼ˆè·³è¿‡ JavaScript æ¸²æŸ“ï¼‰
doc = firecrawl.scrape(
    "https://example.com",
    formats=["markdown"],
    max_age=172800000  # ä½¿ç”¨2å¤©å†…ç¼“å­˜
)
```

**é€‚ç”¨åœºæ™¯**:

- é™æ€ç½‘ç«™
- é™ä½æˆæœ¬
- æ‰¹é‡å¿«é€Ÿé‡‡é›†
- å®šæœŸæ›´æ–°å†…å®¹

---

### 2ï¸âƒ£ Crawlï¼ˆç½‘ç«™çˆ¬å–ï¼‰

#### åŸºç¡€çˆ¬å–

```python
# çˆ¬å–æ•´ä¸ªç½‘ç«™ï¼ˆè‡ªåŠ¨å‘ç°é“¾æ¥ï¼‰
docs = firecrawl.crawl(
    url="https://docs.firecrawl.dev",
    limit=10,  # æœ€å¤šçˆ¬å–10ä¸ªé¡µé¢
    max_depth=2  # æœ€å¤§æ·±åº¦2å±‚
)

for doc in docs:
    print(f"{doc.url}: {len(doc.markdown)} å­—ç¬¦")
```

**é€‚ç”¨åœºæ™¯**:

- æ–‡æ¡£ç«™ç‚¹å®Œæ•´é‡‡é›†
- åšå®¢å½’æ¡£
- äº§å“ç›®å½•çˆ¬å–
- çŸ¥è¯†åº“å»ºè®¾

#### Webhook å¼‚æ­¥çˆ¬å–

```python
# å¼‚æ­¥çˆ¬å–ï¼ˆå¤§å‹ç½‘ç«™ï¼‰
job_id = firecrawl.async_crawl(
    url="https://example.com",
    limit=1000,
    webhook="https://your-server.com/webhook"
)

# Webhook æ¥æ”¶å™¨ï¼ˆFastAPI ç¤ºä¾‹ï¼‰
from fastapi import FastAPI, Request

app = FastAPI()

@app.post("/webhook")
async def webhook(request: Request):
    data = await request.json()

    if data["status"] == "completed":
        # å¤„ç†å®Œæˆçš„æ•°æ®
        docs = data["data"]
        print(f"çˆ¬å–å®Œæˆ: {len(docs)} ä¸ªé¡µé¢")

    return {"received": True}
```

**é€‚ç”¨åœºæ™¯**:

- å¤§å‹ç½‘ç«™çˆ¬å–ï¼ˆ100+ é¡µé¢ï¼‰
- é•¿æ—¶é—´è¿è¡Œä»»åŠ¡
- åå°æ•°æ®é‡‡é›†
- å®šæ—¶çˆ¬å–ä»»åŠ¡

#### è·¯å¾„è¿‡æ»¤

```python
# åªçˆ¬å–ç‰¹å®šè·¯å¾„
docs = firecrawl.crawl(
    url="https://example.com",
    include_paths=["/blog/*", "/docs/*"],  # åªåŒ…å«è¿™äº›è·¯å¾„
    exclude_paths=["/admin/*", "/api/*"],  # æ’é™¤è¿™äº›è·¯å¾„
    limit=50
)
```

**é€‚ç”¨åœºæ™¯**:

- ç‰¹å®šæ ç›®é‡‡é›†
- æ’é™¤æ— ç”¨é¡µé¢
- é™ä½çˆ¬å–æˆæœ¬
- ç²¾å‡†å†…å®¹è·å–

#### å®æ—¶è¿›åº¦ç›‘æ§

```python
# ç›‘æ§çˆ¬å–è¿›åº¦
job = firecrawl.crawl(
    url="https://example.com",
    limit=100,
    poll_interval=5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
)

# å®æ—¶æ‰“å°è¿›åº¦
for status in job:
    print(f"è¿›åº¦: {status.completed}/{status.total}")
    print(f"å½“å‰é¡µé¢: {status.current_url}")
```

**é€‚ç”¨åœºæ™¯**:

- ç”¨æˆ·ç•Œé¢è¿›åº¦æ˜¾ç¤º
- ä»»åŠ¡ç›‘æ§
- è°ƒè¯•å’Œæµ‹è¯•
- æˆæœ¬é¢„ä¼°

---

### 3ï¸âƒ£ Mapï¼ˆç½‘ç«™åœ°å›¾ï¼‰

#### å¿«é€Ÿç”Ÿæˆç½‘ç«™åœ°å›¾

```python
# å¿«é€Ÿå‘ç°ç½‘ç«™æ‰€æœ‰é“¾æ¥
urls = firecrawl.map(
    url="https://firecrawl.dev",
    limit=100,  # æœ€å¤šå‘ç°100ä¸ªé“¾æ¥
    sitemap="include"  # åŒ…å« sitemap.xml
)

print(f"å‘ç° {len(urls.links)} ä¸ªé“¾æ¥:")
for link in urls.links:
    print(f"- {link}")
```

**é€‚ç”¨åœºæ™¯**:

- ç½‘ç«™ç»“æ„åˆ†æ
- SEO å®¡è®¡
- å†…å®¹æ¸…å•
- çˆ¬å–å‰è§„åˆ’

#### æœç´¢ç‰¹å®šå†…å®¹

```python
# æœç´¢åŒ…å«ç‰¹å®šå…³é”®è¯çš„é¡µé¢
urls = firecrawl.map(
    url="https://example.com",
    search="pricing",  # æœç´¢åŒ…å« "pricing" çš„é¡µé¢
    limit=50
)

print(f"æ‰¾åˆ° {len(urls.links)} ä¸ªç›¸å…³é¡µé¢")
```

**é€‚ç”¨åœºæ™¯**:

- ç‰¹å®šé¡µé¢å‘ç°
- å†…å®¹å®¡è®¡
- ç«å“åˆ†æ
- æ•°æ®é‡‡é›†å‡†å¤‡

---

### 4ï¸âƒ£ Searchï¼ˆæ™ºèƒ½æœç´¢ï¼‰

#### åŸºç¡€æœç´¢

```python
# æœç´¢äº’è”ç½‘å†…å®¹
results = firecrawl.search(
    query="firecrawl python examples",
    limit=10
)

for result in results:
    print(f"{result.title}")
    print(f"URL: {result.url}")
    print(f"æ‘˜è¦: {result.snippet}\n")
```

**é€‚ç”¨åœºæ™¯**:

- ç«å“ç›‘æ§
- å¸‚åœºè°ƒç ”
- å†…å®¹å‘ç°
- æ•°æ®é‡‡é›†æºæŸ¥æ‰¾

#### æœç´¢ + çˆ¬å–

```python
# æœç´¢å¹¶ç«‹å³çˆ¬å–ç»“æœé¡µé¢
results = firecrawl.search(
    query="best restaurants in hawaii",
    limit=5,
    scrape_options={
        "formats": ["markdown"],
        "only_main_content": True
    }
)

for result in results:
    print(f"{result.title}")
    print(result.markdown[:200])  # å‰200å­—ç¬¦
```

**é€‚ç”¨åœºæ™¯**:

- ä¸€é”®æ•°æ®é‡‡é›†
- å†…å®¹èšåˆ
- ç ”ç©¶è‡ªåŠ¨åŒ–
- RAG æ•°æ®æº

#### æ—¶é—´èŒƒå›´è¿‡æ»¤

```python
# æœç´¢æœ€è¿‘ä¸€å‘¨çš„å†…å®¹
results = firecrawl.search(
    query="AI news",
    limit=10,
    time="week"  # day, week, month, year
)
```

**é€‚ç”¨åœºæ™¯**:

- æ–°é—»é‡‡é›†
- è¶‹åŠ¿åˆ†æ
- æ—¶æ•ˆæ€§å†…å®¹
- å®šæœŸæ›´æ–°

---

### 5ï¸âƒ£ Batch Scrapeï¼ˆæ‰¹é‡çˆ¬å–ï¼‰

#### åŸºç¡€æ‰¹é‡çˆ¬å–

```python
# æ‰¹é‡çˆ¬å–å¤šä¸ª URL
urls = [
    "https://example.com/page1",
    "https://example.com/page2",
    "https://example.com/page3"
]

job = firecrawl.batch_scrape(
    urls=urls,
    formats=["markdown"],
    poll_interval=2,
    wait_timeout=120
)

print(f"çŠ¶æ€: {job.status}")
print(f"å®Œæˆ: {job.completed}/{job.total}")

# è®¿é—®ç»“æœ
for doc in job.data:
    print(f"{doc.url}: {len(doc.markdown)} å­—ç¬¦")
```

**é€‚ç”¨åœºæ™¯**:

- å·²çŸ¥ URL åˆ—è¡¨é‡‡é›†
- äº§å“è¯¦æƒ…æ‰¹é‡è·å–
- æ–°é—»æ–‡ç« æ‰¹é‡çˆ¬å–
- æ•°æ®æ‰¹é‡æ›´æ–°

#### å¼‚æ­¥æ‰¹é‡çˆ¬å–

```python
# å¼‚æ­¥å¯åŠ¨æ‰¹é‡ä»»åŠ¡
job_id = firecrawl.start_batch_scrape(
    urls=[f"https://example.com/page{i}" for i in range(100)],
    formats=["markdown"],
    webhook="https://your-server.com/webhook"
)

print(f"ä»»åŠ¡ID: {job_id}")

# ç¨åæ£€æŸ¥çŠ¶æ€
job = firecrawl.check_batch_status(job_id)
print(f"è¿›åº¦: {job.completed}/{job.total}")
```

**é€‚ç”¨åœºæ™¯**:

- å¤§æ‰¹é‡ URLï¼ˆ100+ï¼‰
- åå°æ•°æ®é‡‡é›†
- å®šæ—¶ä»»åŠ¡
- é•¿æ—¶é—´è¿è¡Œ

#### é”™è¯¯å¤„ç†

```python
# æ‰¹é‡çˆ¬å–å¹¶å¤„ç†é”™è¯¯
job = firecrawl.batch_scrape(urls=urls, formats=["markdown"])

for doc in job.data:
    if doc.error:
        print(f"å¤±è´¥: {doc.url} - {doc.error}")
    else:
        print(f"æˆåŠŸ: {doc.url}")
```

**é€‚ç”¨åœºæ™¯**:

- å¯é æ€§è¦æ±‚é«˜
- é”™è¯¯æ—¥å¿—è®°å½•
- é‡è¯•æœºåˆ¶
- è´¨é‡ç›‘æ§

---

### 6ï¸âƒ£ Extractï¼ˆæ•°æ®æå–ï¼‰

#### åŸºç¡€æå–

```python
# ä»ç½‘é¡µæå–ç»“æ„åŒ–æ•°æ®
schema = {
    "type": "object",
    "properties": {
        "description": {"type": "string"}
    },
    "required": ["description"]
}

res = firecrawl.extract(
    urls=["https://docs.firecrawl.dev"],
    prompt="Extract the page description",
    schema=schema
)

print(res.data["description"])
```

**é€‚ç”¨åœºæ™¯**:

- éç»“æ„åŒ–æ•°æ®æå–
- AI è¾…åŠ©è§£æ
- å¤æ‚é¡µé¢å¤„ç†
- æ™ºèƒ½å­—æ®µè¯†åˆ«

#### æ—  Schema æå–

```python
# ä½¿ç”¨ AI è‡ªåŠ¨æ¨å¯¼ç»“æ„
res = firecrawl.extract(
    urls=["https://example.com/product"],
    prompt="Extract product information including name, price, and reviews"
)

print(res.data)  # AI è‡ªåŠ¨ç”Ÿæˆçš„ç»“æ„
```

**é€‚ç”¨åœºæ™¯**:

- æ¢ç´¢æ€§æ•°æ®åˆ†æ
- ç»“æ„ä¸æ˜ç¡®çš„é¡µé¢
- å¿«é€ŸåŸå‹å¼€å‘
- çµæ´»æ•°æ®æå–

#### Web Search + Extract

```python
# æœç´¢äº’è”ç½‘å¹¶æå–æ•°æ®
res = firecrawl.extract(
    prompt="Find the top 3 AI tools launched in 2024",
    enable_web_search=True,
    schema={
        "type": "array",
        "items": {
            "type": "object",
            "properties": {
                "name": {"type": "string"},
                "description": {"type": "string"},
                "url": {"type": "string"}
            }
        }
    }
)

for tool in res.data:
    print(f"{tool['name']}: {tool['description']}")
```

**é€‚ç”¨åœºæ™¯**:

- å¸‚åœºè°ƒç ”
- ç«å“åˆ†æ
- å†…å®¹èšåˆ
- ç ”ç©¶è‡ªåŠ¨åŒ–

---

## ğŸ—ï¸ å…¨æ ˆé¡¹ç›®æ¨¡æ¿è¯¦è§£

### 1. Open Lovable - RAG èŠå¤©æœºå™¨äºº

**æŠ€æœ¯æ ˆ**:

- Next.js 14 (App Router)
- Firecrawl API
- OpenAI API
- Pinecone (å‘é‡æ•°æ®åº“)
- Tailwind CSS

**æ ¸å¿ƒåŠŸèƒ½**:

- çˆ¬å–ç½‘ç«™å†…å®¹
- å‘é‡åŒ–å­˜å‚¨
- è¯­ä¹‰æœç´¢
- æµå¼å¯¹è¯

**ä½¿ç”¨åœºæ™¯**:

- ç½‘ç«™å®¢æœæœºå™¨äºº
- çŸ¥è¯†åº“é—®ç­”
- æ–‡æ¡£åŠ©æ‰‹
- å­¦ä¹ è¾…å¯¼

**å¿«é€Ÿå¯åŠ¨**:

```bash
git clone https://github.com/firecrawl/open-lovable
cd open-lovable
npm install
cp .env.example .env
# é…ç½® API å¯†é’¥
npm run dev
```

---

### 2. Open Agent Builder - AI ä»£ç†æ„å»ºå™¨

**æŠ€æœ¯æ ˆ**:

- Next.js 14
- Firecrawl API
- LangChain
- Supabase
- shadcn/ui

**æ ¸å¿ƒåŠŸèƒ½**:

- å¯è§†åŒ–ä»£ç†æ„å»º
- ç½‘é¡µçˆ¬å–é›†æˆ
- å·¥ä½œæµç¼–æ’
- ä»£ç†éƒ¨ç½²

**ä½¿ç”¨åœºæ™¯**:

- è‡ªåŠ¨åŒ–å·¥ä½œæµ
- æ•°æ®é‡‡é›†ä»£ç†
- ç ”ç©¶åŠ©æ‰‹
- å†…å®¹ç”Ÿæˆ

---

### 3. Fireplexity - AI æœç´¢å¼•æ“

**æŠ€æœ¯æ ˆ**:

- Next.js 14
- Firecrawl Search
- OpenAI API
- Vercel AI SDK
- Groq API

**æ ¸å¿ƒåŠŸèƒ½**:

- å®æ—¶æœç´¢
- æµå¼å“åº”
- å¼•ç”¨æ ‡æ³¨
- å¤šæºèšåˆ

**ä½¿ç”¨åœºæ™¯**:

- ç ”ç©¶å·¥å…·
- å®æ—¶é—®ç­”
- æ–°é—»èšåˆ
- å¸‚åœºè°ƒç ”

---

### 4. FireGEO - SaaS å“ç‰Œç›‘æ§

**æŠ€æœ¯æ ˆ**:

- Next.js 14
- Firecrawl API
- Supabase
- Stripe
- PostHog

**æ ¸å¿ƒåŠŸèƒ½**:

- å“ç‰ŒæåŠç›‘æ§
- è‡ªåŠ¨åŒ–æŠ¥å‘Š
- ç”¨æˆ·è®¤è¯
- è®¢é˜…è®¡è´¹

**ä½¿ç”¨åœºæ™¯**:

- å“ç‰Œç›‘æ§
- ç«å“åˆ†æ
- èˆ†æƒ…ç›‘æµ‹
- SaaS äº§å“

---

### 5. Fire Enrich - æ•°æ®ä¸°å¯ŒåŒ–

**æŠ€æœ¯æ ˆ**:

- Next.js 14
- Firecrawl API
- OpenAI API
- CSV å¤„ç†

**æ ¸å¿ƒåŠŸèƒ½**:

- é‚®ç®±åŸŸåæå–
- ç½‘ç«™çˆ¬å–
- AI æ•°æ®æå–
- CSV å¯¼å‡º

**ä½¿ç”¨åœºæ™¯**:

- é”€å”®çº¿ç´¢ä¸°å¯ŒåŒ–
- å®¢æˆ·æ•°æ®è¡¥å…¨
- å¸‚åœºè°ƒç ”
- CRM æ•°æ®å¢å¼º

---

### 6. Firesearch - æ·±åº¦ç ”ç©¶å·¥å…·

**æŠ€æœ¯æ ˆ**:

- Next.js 14
- Firecrawl Search
- OpenAI API
- å¼•ç”¨éªŒè¯

**æ ¸å¿ƒåŠŸèƒ½**:

- å¤šæ­¥éª¤ç ”ç©¶
- äº‹å®éªŒè¯
- å¼•ç”¨è¿½è¸ª
- æ·±åº¦åˆ†æ

**ä½¿ç”¨åœºæ™¯**:

- å­¦æœ¯ç ”ç©¶
- æŠ•èµ„åˆ†æ
- æ–°é—»æ ¸æŸ¥
- ä¸“ä¸šæŠ¥å‘Š

---

### 7. Firestarter - ç½‘ç«™èŠå¤©æœºå™¨äºº

**æŠ€æœ¯æ ˆ**:

- Next.js 14
- Firecrawl Crawl
- OpenAI API
- Pinecone

**æ ¸å¿ƒåŠŸèƒ½**:

- ä¸€é”®ç½‘ç«™çˆ¬å–
- è‡ªåŠ¨å‘é‡åŒ–
- åµŒå…¥å¼èŠå¤©
- å¿«é€Ÿéƒ¨ç½²

**ä½¿ç”¨åœºæ™¯**:

- ç½‘ç«™å®¢æœ
- äº§å“æ–‡æ¡£åŠ©æ‰‹
- åœ¨çº¿æ”¯æŒ
- çŸ¥è¯†åº“é—®ç­”

---

### 8. AI Ready Website - ç½‘ç«™ç»“æ„åŒ–

**æŠ€æœ¯æ ˆ**:

- Python
- Firecrawl API
- JSON Schema
- LLM é›†æˆ

**æ ¸å¿ƒåŠŸèƒ½**:

- ç½‘ç«™çˆ¬å–
- ç»“æ„åŒ–è½¬æ¢
- Schema ç”Ÿæˆ
- AI-ready è¾“å‡º

**ä½¿ç”¨åœºæ™¯**:

- AI è®­ç»ƒæ•°æ®å‡†å¤‡
- ç½‘ç«™å½’æ¡£
- å†…å®¹è¿ç§»
- æ•°æ®æ ‡å‡†åŒ–

---

### 9. Open Researcher - AI ç ”ç©¶åŠ©æ‰‹

**æŠ€æœ¯æ ˆ**:

- Next.js 14
- Firecrawl Search
- LangChain
- å¤šæ­¥éª¤æ¨ç†

**æ ¸å¿ƒåŠŸèƒ½**:

- è‡ªåŠ¨ç ”ç©¶è§„åˆ’
- å¤šæºæ•°æ®é‡‡é›†
- æ™ºèƒ½åˆ†æ
- æŠ¥å‘Šç”Ÿæˆ

**ä½¿ç”¨åœºæ™¯**:

- å¸‚åœºç ”ç©¶
- å­¦æœ¯è°ƒç ”
- å°½èŒè°ƒæŸ¥
- å†…å®¹åˆ›ä½œ

---

## ğŸ¯ HawaiiHub ä¸“é¡¹åº”ç”¨åœºæ™¯

### åœºæ™¯ 1: å¤å¨å¤·æ–°é—»èšåˆ

**æ¨èæ¨¡æ¿**:

- Crawl + Batch Scrape
- Webhook å¼‚æ­¥å¤„ç†

**å®ç°æ–¹æ¡ˆ**:

```python
from firecrawl import Firecrawl

firecrawl = Firecrawl(api_key=os.getenv("FIRECRAWL_API_KEY"))

# æ–°é—»æºåˆ—è¡¨
NEWS_SOURCES = [
    "https://www.hawaiinewsnow.com/",
    "https://www.staradvertiser.com/",
    "https://www.civilbeat.org/"
]

# 1. ä½¿ç”¨ Map å‘ç°æ–‡ç« é“¾æ¥
for source in NEWS_SOURCES:
    urls = firecrawl.map(
        url=source,
        search="news",  # åªæŸ¥æ‰¾æ–°é—»ç›¸å…³é¡µé¢
        limit=50
    )

    # 2. æ‰¹é‡çˆ¬å–æ–‡ç« 
    articles = firecrawl.batch_scrape(
        urls=urls.links[:20],  # æ¯ä¸ªæºçˆ¬å–20ç¯‡
        formats=["markdown"],
        poll_interval=5
    )

    # 3. ä¿å­˜æ•°æ®
    for article in articles.data:
        save_article(article)
```

---

### åœºæ™¯ 2: Yelp é¤å…ä¿¡æ¯é‡‡é›†

**æ¨èæ¨¡æ¿**:

- Scrape + JSON Extract
- ä»£ç†æ¨¡å¼ï¼ˆç»•è¿‡é™åˆ¶ï¼‰

**å®ç°æ–¹æ¡ˆ**:

```python
# å®šä¹‰é¤å…æ•°æ®ç»“æ„
RESTAURANT_SCHEMA = {
    "type": "object",
    "properties": {
        "name": {"type": "string"},
        "rating": {"type": "number"},
        "price_range": {"type": "string"},
        "address": {"type": "string"},
        "phone": {"type": "string"},
        "cuisine": {"type": "array", "items": {"type": "string"}},
        "hours": {"type": "object"},
        "reviews_count": {"type": "number"}
    }
}

# æœç´¢æª€é¦™å±±ä¸­é¤
search_url = "https://www.yelp.com/search?find_desc=Chinese&find_loc=Honolulu,+HI"

# 1. çˆ¬å–æœç´¢ç»“æœé¡µ
search_page = firecrawl.scrape(
    url=search_url,
    formats=["markdown"],
    location={"country": "US"}  # ä½¿ç”¨ç¾å›½ä»£ç†
)

# 2. æå–é¤å…é“¾æ¥ï¼ˆéœ€è¦è‡ªå®šä¹‰è§£æï¼‰
restaurant_urls = extract_restaurant_urls(search_page.markdown)

# 3. æ‰¹é‡çˆ¬å–é¤å…è¯¦æƒ…å¹¶æå–ç»“æ„åŒ–æ•°æ®
restaurants = firecrawl.batch_scrape(
    urls=restaurant_urls,
    formats=[{
        "type": "json",
        "schema": RESTAURANT_SCHEMA
    }]
)

# 4. ä¿å­˜åˆ°æ•°æ®åº“
for restaurant in restaurants.data:
    save_restaurant(restaurant.extract)
```

---

### åœºæ™¯ 3: Craigslist ç§Ÿæˆ¿ç›‘æ§

**æ¨èæ¨¡æ¿**:

- Search + Crawl
- Webhook å®æ—¶é€šçŸ¥

**å®ç°æ–¹æ¡ˆ**:

```python
# ç§Ÿæˆ¿ä¿¡æ¯ç»“æ„
LISTING_SCHEMA = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "price": {"type": "number"},
        "bedrooms": {"type": "number"},
        "bathrooms": {"type": "number"},
        "sqft": {"type": "number"},
        "address": {"type": "string"},
        "posted_date": {"type": "string"},
        "description": {"type": "string"}
    }
}

# æœç´¢æª€é¦™å±±ç§Ÿæˆ¿ï¼ˆä»·æ ¼ < $2000ï¼‰
search_url = "https://honolulu.craigslist.org/search/apa?max_price=2000"

# ä½¿ç”¨ Webhook ç›‘æ§æ–°æˆ¿æº
job_id = firecrawl.async_crawl(
    url=search_url,
    limit=100,
    webhook="https://hawaiihub.net/api/housing/webhook",
    formats=[{
        "type": "json",
        "schema": LISTING_SCHEMA
    }]
)

# Webhook æ¥æ”¶å™¨ï¼ˆFastAPIï¼‰
@app.post("/api/housing/webhook")
async def housing_webhook(request: Request):
    data = await request.json()

    if data["type"] == "page":
        # æ–°æˆ¿æºå‘ç°
        listing = data["data"]["extract"]

        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
        if not listing_exists(listing):
            # å‘é€é€šçŸ¥
            send_notification(listing)
            # ä¿å­˜æ•°æ®åº“
            save_listing(listing)

    return {"received": True}
```

---

### åœºæ™¯ 4: åäººç¤¾åŒºæ´»åŠ¨é‡‡é›†

**æ¨èæ¨¡æ¿**:

- Map + Extract
- å®šæ—¶ä»»åŠ¡

**å®ç°æ–¹æ¡ˆ**:

```python
# æ´»åŠ¨ä¿¡æ¯ç»“æ„
EVENT_SCHEMA = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "date": {"type": "string"},
        "time": {"type": "string"},
        "location": {"type": "string"},
        "organizer": {"type": "string"},
        "description": {"type": "string"},
        "registration_url": {"type": "string"}
    }
}

# åäººç¤¾åŒºç½‘ç«™åˆ—è¡¨
COMMUNITY_SITES = [
    "https://www.kauaichineseassociation.org/",
    "https://www.chinesechamber.com/",
    # æ›´å¤šç¤¾åŒºç½‘ç«™...
]

# å®šæ—¶ä»»åŠ¡ï¼ˆæ¯å¤©è¿è¡Œï¼‰
def collect_community_events():
    for site in COMMUNITY_SITES:
        # 1. å‘ç°æ´»åŠ¨é¡µé¢
        urls = firecrawl.map(
            url=site,
            search="event",  # æŸ¥æ‰¾æ´»åŠ¨ç›¸å…³é¡µé¢
            limit=20
        )

        # 2. æå–æ´»åŠ¨ä¿¡æ¯
        events = firecrawl.extract(
            urls=urls.links,
            prompt="Extract event information including title, date, time, location, and description",
            schema=EVENT_SCHEMA
        )

        # 3. ä¿å­˜åˆ°æ—¥å†
        for event in events.data:
            save_event(event)

# ä½¿ç”¨ schedule åº“å®šæ—¶è¿è¡Œ
import schedule
schedule.every().day.at("06:00").do(collect_community_events)
```

---

## ğŸ“Š æ¨¡æ¿é€‰æ‹©å†³ç­–æ ‘

```
éœ€è¦é‡‡é›†ä»€ä¹ˆï¼Ÿ
â”œâ”€â”€ å•ä¸ªç½‘é¡µå†…å®¹
â”‚   â”œâ”€â”€ ç®€å•æ–‡æœ¬ â†’ Scrape (Markdown)
â”‚   â”œâ”€â”€ ç»“æ„åŒ–æ•°æ® â†’ Scrape (JSON)
â”‚   â””â”€â”€ éœ€è¦æˆªå›¾ â†’ Scrape (Screenshot)
â”‚
â”œâ”€â”€ å¤šä¸ªå·²çŸ¥ URL
â”‚   â”œâ”€â”€ < 10 ä¸ª â†’ Batch Scrape (åŒæ­¥)
â”‚   â””â”€â”€ > 10 ä¸ª â†’ Batch Scrape (å¼‚æ­¥ + Webhook)
â”‚
â”œâ”€â”€ æ•´ä¸ªç½‘ç«™
â”‚   â”œâ”€â”€ å°å‹ç½‘ç«™ (< 100 é¡µ) â†’ Crawl (åŒæ­¥)
â”‚   â””â”€â”€ å¤§å‹ç½‘ç«™ (> 100 é¡µ) â†’ Crawl (å¼‚æ­¥ + Webhook)
â”‚
â”œâ”€â”€ ä¸çŸ¥é“å…·ä½“ URL
â”‚   â”œâ”€â”€ å…ˆæ¢ç´¢ç½‘ç«™ â†’ Map (å‘ç°æ‰€æœ‰é“¾æ¥)
â”‚   â””â”€â”€ æœç´¢äº’è”ç½‘ â†’ Search (æŸ¥æ‰¾ç›¸å…³å†…å®¹)
â”‚
â””â”€â”€ å¤æ‚æ•°æ®æå–
    â”œâ”€â”€ æœ‰æ˜ç¡®ç»“æ„ â†’ Extract (Schema)
    â””â”€â”€ ç»“æ„ä¸ç¡®å®š â†’ Extract (Prompt Only)
```

---

## ğŸ› ï¸ å¼€å‘å·¥å…·å’Œé…ç½®

### ç¯å¢ƒå˜é‡æ¨¡æ¿

```bash
# .env
# Firecrawl API é…ç½®
FIRECRAWL_API_KEY=fc-YOUR-API-KEY
FIRECRAWL_API_KEY_BACKUP_1=fc-BACKUP-KEY-1
FIRECRAWL_API_KEY_BACKUP_2=fc-BACKUP-KEY-2
FIRECRAWL_API_KEY_BACKUP_3=fc-BACKUP-KEY-3

# API é…ç½®
FIRECRAWL_API_URL=https://api.firecrawl.dev
FIRECRAWL_TIMEOUT=60
FIRECRAWL_MAX_RETRIES=3

# æˆæœ¬æ§åˆ¶
FIRECRAWL_DAILY_BUDGET=10.0
FIRECRAWL_MONTHLY_BUDGET=300.0

# Webhook é…ç½®
WEBHOOK_URL=https://your-domain.com/webhook
WEBHOOK_SECRET=your-webhook-secret

# æ•°æ®åº“é…ç½®ï¼ˆå¯é€‰ï¼‰
DATABASE_URL=postgresql://user:password@localhost:5432/hawaiihub
REDIS_URL=redis://localhost:6379

# OpenAI APIï¼ˆç”¨äº Extractï¼‰
OPENAI_API_KEY=sk-YOUR-OPENAI-KEY
```

---

### Python é…ç½®æ–‡ä»¶æ¨¡æ¿

```python
# config/firecrawl_config.py
import os
from dotenv import load_dotenv
from firecrawl import Firecrawl

load_dotenv()

class FirecrawlConfig:
    """Firecrawl é…ç½®ç±»"""

    # API å¯†é’¥
    API_KEY = os.getenv("FIRECRAWL_API_KEY")
    BACKUP_KEYS = [
        os.getenv("FIRECRAWL_API_KEY_BACKUP_1"),
        os.getenv("FIRECRAWL_API_KEY_BACKUP_2"),
        os.getenv("FIRECRAWL_API_KEY_BACKUP_3"),
    ]

    # API é…ç½®
    API_URL = os.getenv("FIRECRAWL_API_URL", "https://api.firecrawl.dev")
    TIMEOUT = int(os.getenv("FIRECRAWL_TIMEOUT", "60"))
    MAX_RETRIES = int(os.getenv("FIRECRAWL_MAX_RETRIES", "3"))

    # æˆæœ¬æ§åˆ¶
    DAILY_BUDGET = float(os.getenv("FIRECRAWL_DAILY_BUDGET", "10.0"))
    MONTHLY_BUDGET = float(os.getenv("FIRECRAWL_MONTHLY_BUDGET", "300.0"))

    # Webhook
    WEBHOOK_URL = os.getenv("WEBHOOK_URL")
    WEBHOOK_SECRET = os.getenv("WEBHOOK_SECRET")

    @classmethod
    def get_client(cls) -> Firecrawl:
        """è·å– Firecrawl å®¢æˆ·ç«¯"""
        return Firecrawl(api_key=cls.API_KEY)

    @classmethod
    def get_backup_client(cls, index: int = 0) -> Firecrawl:
        """è·å–å¤‡ç”¨å®¢æˆ·ç«¯"""
        if index < len(cls.BACKUP_KEYS):
            return Firecrawl(api_key=cls.BACKUP_KEYS[index])
        raise ValueError("å¤‡ç”¨å¯†é’¥ç´¢å¼•è¶…å‡ºèŒƒå›´")

# ä½¿ç”¨ç¤ºä¾‹
firecrawl = FirecrawlConfig.get_client()
```

---

## ğŸ“ æœ€ä½³å®è·µæ€»ç»“

### æ€§èƒ½ä¼˜åŒ–

1. **ä½¿ç”¨ç¼“å­˜**

```python
# ä½¿ç”¨ max_age å‚æ•°å¯ç”¨ç¼“å­˜
doc = firecrawl.scrape(
    "https://example.com",
    formats=["markdown"],
    max_age=172800000  # 2å¤©ç¼“å­˜
)
```

2. **æ‰¹é‡æ“ä½œ**

```python
# ä¼˜å…ˆä½¿ç”¨ batch_scrape è€Œéå¾ªç¯ scrape
# âŒ é”™è¯¯
for url in urls:
    doc = firecrawl.scrape(url)

# âœ… æ­£ç¡®
docs = firecrawl.batch_scrape(urls)
```

3. **å¼‚æ­¥å¤„ç†**

```python
# å¤§æ‰¹é‡ä»»åŠ¡ä½¿ç”¨å¼‚æ­¥ + Webhook
job_id = firecrawl.async_crawl(
    url="https://large-site.com",
    webhook="https://your-server.com/webhook"
)
```

---

### æˆæœ¬æ§åˆ¶

1. **åˆç†è®¾ç½®é™åˆ¶**

```python
# ä½¿ç”¨ limit æ§åˆ¶çˆ¬å–æ•°é‡
docs = firecrawl.crawl(
    url="https://example.com",
    limit=50,  # æœ€å¤š50é¡µ
    max_depth=2  # æœ€å¤š2å±‚æ·±åº¦
)
```

2. **ä½¿ç”¨è·¯å¾„è¿‡æ»¤**

```python
# åªçˆ¬å–éœ€è¦çš„å†…å®¹
docs = firecrawl.crawl(
    url="https://example.com",
    include_paths=["/blog/*"],  # åªçˆ¬åšå®¢
    exclude_paths=["/admin/*", "/api/*"]  # æ’é™¤ç®¡ç†å’ŒAPI
)
```

3. **ç›‘æ§ä½¿ç”¨é‡**

```python
# è®°å½•æ¯æ¬¡ API è°ƒç”¨
import logging

def track_usage(operation, cost):
    logging.info(f"{operation}: ${cost:.4f}")
    # ä¿å­˜åˆ°æ•°æ®åº“æˆ–ç›‘æ§ç³»ç»Ÿ
```

---

### é”™è¯¯å¤„ç†

```python
from firecrawl import Firecrawl, FirecrawlError

firecrawl = Firecrawl(api_key=os.getenv("FIRECRAWL_API_KEY"))

def safe_scrape(url: str, max_retries: int = 3):
    """å®‰å…¨çˆ¬å–ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    for attempt in range(max_retries):
        try:
            doc = firecrawl.scrape(
                url=url,
                formats=["markdown"]
            )
            return doc

        except FirecrawlError as e:
            if "rate limit" in str(e).lower():
                # åˆ‡æ¢åˆ°å¤‡ç”¨å¯†é’¥
                firecrawl = FirecrawlConfig.get_backup_client(attempt)
                continue

            elif attempt < max_retries - 1:
                # ç­‰å¾…åé‡è¯•
                import time
                wait_time = 2 ** attempt
                time.sleep(wait_time)
                continue

            else:
                logging.error(f"çˆ¬å–å¤±è´¥ {url}: {e}")
                return None
```

---

## ğŸ“ å­¦ä¹ è·¯å¾„

### åˆå­¦è€…ï¼ˆ1-2 å¤©ï¼‰

1. âœ… é˜…è¯» [å¿«é€Ÿå¼€å§‹æŒ‡å—](../quickstart.md)
2. âœ… è¿è¡ŒåŸºç¡€ Scrape ç¤ºä¾‹
3. âœ… ç†è§£ Markdown vs JSON æ ¼å¼
4. âœ… å°è¯• Map åŠŸèƒ½å‘ç°ç½‘ç«™ç»“æ„

### ä¸­çº§ï¼ˆ3-5 å¤©ï¼‰

1. âœ… å­¦ä¹  Crawl å’Œ Batch Scrape
2. âœ… é…ç½® Webhook å¼‚æ­¥å¤„ç†
3. âœ… ä½¿ç”¨ Extract æå–ç»“æ„åŒ–æ•°æ®
4. âœ… å®ç°é”™è¯¯å¤„ç†å’Œé‡è¯•

### é«˜çº§ï¼ˆ1-2 å‘¨ï¼‰

1. âœ… éƒ¨ç½²å…¨æ ˆé¡¹ç›®ï¼ˆOpen Lovable/Fireplexityï¼‰
2. âœ… å®ç°æˆæœ¬ç›‘æ§å’Œä¼˜åŒ–
3. âœ… æ„å»ºç”Ÿäº§çº§æ•°æ®ç®¡é“
4. âœ… é›†æˆåˆ°ç°æœ‰ç³»ç»Ÿ

---

## ğŸ“š å‚è€ƒèµ„æº

### å®˜æ–¹æ–‡æ¡£

- [Firecrawl å®˜æ–¹æ–‡æ¡£](https://docs.firecrawl.dev/)
- [API å‚è€ƒ](https://docs.firecrawl.dev/api-reference/introduction)
- [SDK æ–‡æ¡£](https://docs.firecrawl.dev/sdks/python)

### GitHub èµ„æº

- [Firecrawl ä¸»ä»“åº“](https://github.com/mendableai/firecrawl)
- [å®˜æ–¹ç¤ºä¾‹é›†åˆ](https://github.com/firecrawl)
- [ç¤¾åŒºè´¡çŒ®](https://github.com/topics/firecrawl)

### ç¤¾åŒº

- [Discord ç¤¾åŒº](https://discord.gg/firecrawl)
- [Twitter/X](https://twitter.com/mendableai)
- [Blog](https://firecrawl.dev/blog)

---

## âœ… å¿«é€Ÿæ£€æŸ¥æ¸…å•

åœ¨å¼€å§‹ä½¿ç”¨æ¨¡æ¿å‰ï¼Œç¡®ä¿ï¼š

- [ ] å·²å®‰è£… Firecrawl Python SDK (`pip install firecrawl-py`)
- [ ] å·²é…ç½® API å¯†é’¥ç¯å¢ƒå˜é‡
- [ ] å·²é˜…è¯»ç›¸å…³åŠŸèƒ½æ–‡æ¡£
- [ ] äº†è§£æˆæœ¬å’Œé™åˆ¶
- [ ] å‡†å¤‡å¥½æ•°æ®å­˜å‚¨æ–¹æ¡ˆ
- [ ] é…ç½®é”™è¯¯å¤„ç†å’Œæ—¥å¿—
- [ ] æµ‹è¯•å°è§„æ¨¡çˆ¬å–ï¼ˆ< 10 é¡µï¼‰
- [ ] ç›‘æ§ API ä½¿ç”¨é‡

---

**ç»´æŠ¤è€…**: HawaiiHub AI Team
**æœ€åæ›´æ–°**: 2025-10-28
**ç‰ˆæœ¬**: v1.0.0

---

<div align="center">

ğŸ”¥ **å¼€å§‹ä½¿ç”¨ Firecrawl æ¨¡æ¿ï¼ŒåŠ é€Ÿ HawaiiHub æ•°æ®é‡‡é›†ï¼**

**[å¿«é€Ÿå¼€å§‹](#-æ ¸å¿ƒåŠŸèƒ½æ¨¡æ¿è¯¦è§£)** | **[å…¨æ ˆé¡¹ç›®](#-å…¨æ ˆé¡¹ç›®æ¨¡æ¿è¯¦è§£)** | **[HawaiiHub åœºæ™¯](#-hawaiihub-ä¸“é¡¹åº”ç”¨åœºæ™¯)**

</div>
