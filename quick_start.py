#!/usr/bin/env python3
"""Firecrawl å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Firecrawl API çˆ¬å–å¤å¨å¤·æ–°é—»ç½‘ç«™
"""

from datetime import datetime

from firecrawl import FirecrawlApp


# ä½¿ç”¨ä½ çš„ä¸» API å¯†é’¥
API_KEY = "fc-31ebbe4647b84fdc975318d372eebea8"

# åˆå§‹åŒ– Firecrawl å®¢æˆ·ç«¯
app = FirecrawlApp(api_key=API_KEY)


def example_1_basic_scrape():
    """ç¤ºä¾‹ 1: åŸºç¡€çˆ¬å–"""
    print("\n" + "=" * 60)
    print("ğŸ“° ç¤ºä¾‹ 1: çˆ¬å–å¤å¨å¤·æ–°é—»é¦–é¡µ")
    print("=" * 60)

    url = "https://www.hawaiinewsnow.com/"

    print(f"ğŸ”„ çˆ¬å–ä¸­: {url}")
    start_time = datetime.now()

    result = app.scrape(
        url=url,
        formats=["markdown"],
        only_main_content=True,  # åªè¦ä¸»è¦å†…å®¹ï¼Œå»é™¤å¹¿å‘Šå’Œå¯¼èˆªæ 
    )

    elapsed = (datetime.now() - start_time).total_seconds()

    print(f"âœ… çˆ¬å–æˆåŠŸï¼è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"ğŸ“„ æ ‡é¢˜: {getattr(result.metadata, 'title', 'N/A')}")
    print(f"ğŸ“ å†…å®¹é•¿åº¦: {len(result.markdown)} å­—ç¬¦")
    print("\nå‰ 200 å­—ç¬¦é¢„è§ˆ:")
    print(result.markdown[:200] + "...")

    return result


def example_2_batch_scrape():
    """ç¤ºä¾‹ 2: æ‰¹é‡çˆ¬å–å¤šä¸ªæ–°é—»æº"""
    print("\n" + "=" * 60)
    print("ğŸ“° ç¤ºä¾‹ 2: æ‰¹é‡çˆ¬å–å¤å¨å¤·æ–°é—»ç½‘ç«™")
    print("=" * 60)

    news_sources = [
        "https://www.hawaiinewsnow.com/",
        "https://www.staradvertiser.com/",
        "https://www.civilbeat.org/",
    ]

    print(f"ğŸ”„ çˆ¬å– {len(news_sources)} ä¸ªç½‘ç«™...")
    start_time = datetime.now()

    # SDK v2: batch_scrape è¿”å› BatchScrapeJob å¯¹è±¡
    batch_job = app.batch_scrape(
        urls=news_sources, formats=["markdown"], only_main_content=True
    )

    elapsed = (datetime.now() - start_time).total_seconds()

    print(f"âœ… æ‰¹é‡çˆ¬å–å®Œæˆï¼æ€»è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"ğŸ“Š å¹³å‡æ¯ä¸ªç½‘ç«™: {elapsed/len(news_sources):.2f}ç§’")

    # SDK v2: batch_job.data æ˜¯ç»“æœåˆ—è¡¨
    if batch_job.data:
        print(f"âœ… æˆåŠŸçˆ¬å– {len(batch_job.data)} ä¸ªç½‘ç«™\n")
        for i, result in enumerate(batch_job.data, 1):
            url = result.metadata.url if hasattr(result.metadata, 'url') else 'N/A'
            title = result.metadata.title if hasattr(result.metadata, 'title') else 'N/A'
            print(f"{i}. {url}")
            print(f"   æ ‡é¢˜: {title[:50]}")
            print(f"   å†…å®¹: {len(result.markdown)} å­—ç¬¦")
    else:
        print("âš ï¸ æ²¡æœ‰è·å–åˆ°æ•°æ®")

    return batch_job


def example_3_search():
    """ç¤ºä¾‹ 3: æœç´¢åŠŸèƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ” ç¤ºä¾‹ 3: æœç´¢å¤å¨å¤·åäººç¤¾åŒºæ–°é—»")
    print("=" * 60)

    query = "Hawaii Chinese community events å¤å¨å¤·åäººç¤¾åŒº"

    print(f"ğŸ” æœç´¢: {query}")
    start_time = datetime.now()

    # SDK v2: search è¿”å› SearchData å¯¹è±¡
    search_data = app.search(
        query=query, sources=[{"type": "web"}], limit=5  # é™åˆ¶ç»“æœæ•°é‡
    )

    elapsed = (datetime.now() - start_time).total_seconds()

    print(f"âœ… æœç´¢å®Œæˆï¼è€—æ—¶: {elapsed:.2f}ç§’")

    # SDK v2: ç»“æœåœ¨ search_data.web åˆ—è¡¨ä¸­
    if search_data.web:
        print(f"ğŸ“Š æ‰¾åˆ° {len(search_data.web)} ä¸ªç»“æœ")
        for i, result in enumerate(search_data.web, 1):
            print(f"\n{i}. {result.title[:60]}")
            print(f"   URL: {result.url}")
            if result.description:
                print(f"   æè¿°: {result.description[:80]}...")
    else:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç»“æœ")

    return search_data


def example_4_with_cache():
    """ç¤ºä¾‹ 4: ä½¿ç”¨ç¼“å­˜èŠ‚çœæˆæœ¬"""
    print("\n" + "=" * 60)
    print("ğŸ’¾ ç¤ºä¾‹ 4: ä½¿ç”¨ç¼“å­˜åŠŸèƒ½")
    print("=" * 60)

    url = "https://www.firecrawl.dev/"

    # ç¬¬ä¸€æ¬¡çˆ¬å–ï¼ˆæ— ç¼“å­˜ï¼‰
    print("ğŸ”„ ç¬¬ä¸€æ¬¡çˆ¬å–ï¼ˆæ— ç¼“å­˜ï¼‰...")
    start_time = datetime.now()

    result1 = app.scrape(url=url, formats=["markdown"], max_age=3600000)  # ç¼“å­˜ 1 å°æ—¶

    elapsed1 = (datetime.now() - start_time).total_seconds()
    print(f"â±ï¸ è€—æ—¶: {elapsed1:.2f}ç§’")

    # ç¬¬äºŒæ¬¡çˆ¬å–ï¼ˆæœ‰ç¼“å­˜ï¼‰
    print("\nğŸ”„ ç¬¬äºŒæ¬¡çˆ¬å–ï¼ˆæœ‰ç¼“å­˜ï¼‰...")
    start_time = datetime.now()

    result2 = app.scrape(url=url, formats=["markdown"], max_age=3600000)  # ä½¿ç”¨ç¼“å­˜

    elapsed2 = (datetime.now() - start_time).total_seconds()
    print(f"â±ï¸ è€—æ—¶: {elapsed2:.2f}ç§’")

    # å¯¹æ¯”
    print("\nğŸ“Š æ€§èƒ½æå‡:")
    if elapsed2 < elapsed1:
        speedup = (elapsed1 - elapsed2) / elapsed1 * 100
        print(f"   é€Ÿåº¦æå‡: {speedup:.1f}%")
        print(f"   èŠ‚çœæ—¶é—´: {elapsed1 - elapsed2:.2f}ç§’")
        print("   ğŸ’° èŠ‚çœæˆæœ¬: ä½¿ç”¨ç¼“å­˜ï¼Œä¸æ¶ˆè€— API é…é¢")

    return result1, result2


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ”¥" * 30)
    print("   Firecrawl å¿«é€Ÿå¼€å§‹ç¤ºä¾‹")
    print("   HawaiiHub æ–°é—»çˆ¬è™«æ¼”ç¤º")
    print("ğŸ”¥" * 30)

    try:
        # ç¤ºä¾‹ 1: åŸºç¡€çˆ¬å–
        example_1_basic_scrape()

        # ç¤ºä¾‹ 2: æ‰¹é‡çˆ¬å–
        example_2_batch_scrape()

        # ç¤ºä¾‹ 3: æœç´¢åŠŸèƒ½
        example_3_search()

        # ç¤ºä¾‹ 4: ç¼“å­˜åŠŸèƒ½
        example_4_with_cache()

        # æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡ŒæˆåŠŸï¼")
        print("=" * 60)
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("1. é˜…è¯» FIRECRAWL_CLOUD_API_RULES.md å­¦ä¹ é«˜çº§ç”¨æ³•")
        print("2. å®ç°æˆæœ¬ç›‘æ§å’Œé”™è¯¯å¤„ç†")
        print("3. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")
        print("\nğŸ“š æ–‡æ¡£ä½ç½®: /Users/zhiledeng/Downloads/FireShot/")

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        print("\nğŸ’¡ å¯èƒ½çš„åŸå› :")
        print("1. API å¯†é’¥æ— æ•ˆ - å…ˆè¿è¡Œ python test_api_keys.py éªŒè¯")
        print("2. ç½‘ç»œè¿æ¥é—®é¢˜")
        print("3. Firecrawl æœåŠ¡å¼‚å¸¸")
        print("\nğŸ”§ æ•…éšœæ’æŸ¥: æŸ¥çœ‹ FIRECRAWL_CLOUD_SETUP_GUIDE.md")


if __name__ == "__main__":
    main()
